


<HTML>
<HEAD>

<TITLE>September 1991/Standard C</TITLE></HEAD>
<body bgcolor="#ffffff">
<H2><A HREF="../tocsep.htm"><IMG SRC="../../toc.gif" ALT="{back to toc}" WIDTH="54" HEIGHT="54"></A><FONT COLOR="#FF0000">   Columns</FONT></H2>

<hr><h2 align="center"><font color="#800000">Standard C<A name="01FD_00FF"><A name="01FD_00FF"></font></h2><P>
<h3 align="center"><A name="01FD_0000"><A name="01FD_0000">A Math Sampler</h3><P>
<h3 align="center"><font color="#800000">P.J. Plauger</font></h3><hr><blockquote><P>
<P><i><A name="01FD_0000"><A name="01FD_0000">P.J. Plauger is senior editor of The C Users Journal. He is secretary of the ANSI C standards committee, X3J11, and convenor<I></I> <I></I>of the ISO C standards committee, WG14. His latest book is The Standard C Library, published by Prentice-Hall. You can reach<I></I> <I></I>him at <I>PJP%plauger@. uunet.uu.net, uunet!plauger! pjp.</I></i></P><P>
<h4><FONT COLOR="#000080"><A name="01FD_0100">Introduction<A name="01FD_0100"></FONT></h4></P>
For the past two months, I have been discussing the functions declared in <I>&lt;math.h&gt;</I>. I began with a brief history of the evolution of the C math library. (See "Math Functions," <I>Standard C, CUJ</I>, July 1991.) I followed with a guided tour of the seminumerical functions. These illustrate the underlying primitive functions that manipulate floating-point values portably, rapidly, and safely. (See "Math Primitives," <I>Standard C, CUJ</I>, August 1991.)<P>
My aim this month is to show you just a handful of the math functions that constitute the real meat of <I>&lt;math.h&gt;</I>. There are well over a dozen such functions (depending upon how you count pairs with similar requirements). It would take far too much space to show them all. Thus, I focus on a representative few.<P>
I don't want to dwell on this topic at great length for other reasons as well. It takes considerable mathematical sophistication to appreciate, or even care about, many aspects of the math functions. It is not the purpose of this column to indulge such sophisticates. Rather, the purpose of <I>Standard C</I> is to shed light on many interesting aspects of the C language as it has been standardized by ANSI and ISO. That provides information of use to the vast majority of C programmers.<P>
To the extent that the math library is an important component of the C language, you should know something about it. The C Standard contains a few subtleties regarding error reporting and support for IEEE 754 floating-point arithmetic. Sometimes, it is easier to show you examples than to just talk about such subtleties. That was part of my motivation in selecting the particular examples I show here. Beyond that, many of you may have little need or desire to inspect <I>&lt;math.h&gt;</I> at close range.<P>
For those of you who want to see more, you're now in luck. You will find the complete code for <I>&lt;math.h&gt;</I>, and all the rest of the Standard C library, in my new book. <I>The Standard C Library</I> is published by Prentice-Hall, and the code disk is available from the C Users Group. (See the ad near the center of this magazine.)<P>
Inside that book you will also find quite a bit of material from earlier <I>Standard C</I> columns. I have been building toward this opus for some time. If you find a sudden urge to refer back to an earlier column on the Standard C library, you now have an alternative to digging through your old issues of <I>CUJ</I>.<P>
In fact, this particular column represents a kind of watershed. It is the first of a series I intend to base on material <I>from the book</I> instead of the other way around. (No, I don't just cut and paste words between files. The needs and perspective of a magazine article differ in several ways from a technical reference book.) We've barely come halfway through my promised tour of the library. (For the original perspectus, see "With Gun and Reel," <I>Standard C, CUJ</I>, September 1990.)<P>
<h4><FONT COLOR="#000080"><A name="01FD_0101">Function <B><I>sqrt</I><A name="01FD_0101"></B></FONT></h4></P>
<A href="list1.htm">Listing 1</a>
shows the function <I>sqrt</I>, which computes the square root of its argument <I>x</I>, or <I>x</I>1/2. It is in many ways the easiest function to understand, because it is based on the simple but elegant Newton's method. (Make a guess, divide that into the argument, and average guess and quotient to get a better guess.) Still, that approach only works for arguments greater than zero. The function must report an error for negative arguments and handle zero as a special case.<P>
IEEE 754 introduces several other special cases as well. Like the code I showed last month, <I>sqrt</I> must also test for various infinities and not-a-number codes. The actual algorithm almost gets lost in the added complexity.<P>
<I>sqrt</I> partitions a positive, finite <I>x</I>, using <I>_Dunscale</I>, into an exponent <I>e</I> and a fraction <I>f</I>. (I showed the code for <I>_Dunscale</I> last month.) The argument value is <I>f</I>*2<I>e</I>, where <I>f</I> is in the interval [0.5, 1.0). The square root is then <I>f</I> 1/2*2<I>e</I>/2.<P>
The function first computes a quadratic least-squares polynomial fit to <I>f</I>1/2. It then applies Newton's Method three times to obtain the needed precision. Note how the function combines the last two iterations of the algorithm to improve performance slightly. <I>_Dscale</I> (also shown last month) puts the pieces back together. That's all there is to it.<P>
<h4><FONT COLOR="#000080"><A name="01FD_0102">Functions <B><I>cos</I></B> And <B><I>sin<A name="01FD_0102"></B></I></FONT></h4></P>
<A href="list2.htm">Listing 2</a>
shows the function <I>_Sin</I>. It computes <I>sin(x)</I> if <I>qoff</I> is zero and <I>cos(x)</I> if <I>qoff</I> is one. Thus, these two functions become themselves trivial. They are, in fact, also implemented as masking macros in <I>&lt;math.h&gt;</I> to eliminate one level of function call.<P>
Using such a "quadrant offset" for cosine avoids the loss of precision that occurs in adding p/2 to the argument instead. I developed the polynomial approximations from truncated Taylor series by "economizing" them using Chebychev polynomials. (If you don't know what that means, don't worry.)<P>
Reducing the argument to the range [--p/4, p/4] must be done carefully. It is easy enough to determine how many times p/2 should be subtracted from the argument. That determines <I>quad</I>, the quadrant (centered on one of the four axes) in which the angle lies. You need the low-order two bits of <I>quad</I> + <I>qoff</I> to determine whether to compute the cosine or sine and whether to negate the result. Note the way the signed quadrant is converted to an unsigned value so that negative arguments get treated consistenly on all computer architectures.<P>
What you'd like to do at this point is compute <I>quad</I>*p/2 to arbitrary precision. You want to subtract this value from the argument and still have full <I>double</I> precision after the most-significant bits cancel. Given the wide range that floating-point values can assume, that's a tall order. It's also a bit silly. The circular functions become progressively grainier the larger the magnitude of the argument. Beyond some magnitude, all values are indistinguishable from exact multiples of p/2. Some people argue that this is an error condition, but the C Standard doesn't say so. The circular functions must return some sensible value, and report no error, for all finite argument values.<P>
I chose to split the difference. Adapting the approach used by Cody and Waite (see the July installment) in several places, I represent p/2 to "one-and-a-half" times <I>double</I> precision. The header <I>"xmath.h"</I> defines the macro <I>HUGE_RAD</I> as:<P>
<pre>#define  HUGE_RAD  3.14e30</pre>
You can divide an argument up to this magnitude by p/2 and still get an value that you can convert to a <I>long</I> with no fear of overflow. The constant <I>c1</I> represents the most-significant bits of p/2 as a <I>double</I> whose least-significant 32 fraction bits are assuredly zero. (The constant <I>c2</I> supplies a full <I>double</I>'s worth of additional precision.)<P>
That means you can multiply <I>c1</I> by an arbitrary <I>long</I> (converted to <I>double</I>) and get an exact result. Thus, so long as the magnitude of the argument is less than <I>HUGE_RAD</I>, you can develop the reduced argument to full <I>double</I> precision. That's what happens in the expression:<P>
<pre>g = (x - g * c1) - g * c2;</pre>
For arguments larger in magnitude than <I>HUGE_RAD</I>, the function simply slashes off a multiple of 2*p. Note the use of the primitive _<I>Dint</I> to isolate the integer part of a <I>double</I>. Put another way, once the argument goes around about a billion times, <I>sin</I> and <I>cos</I> suddenly stop trying so hard. I felt it was not worth the extra effort needed to extend smooth behavior to larger arguments.<P>
The rest of the function _<I>Sin</I> is straightforward. If the reduced angle <I>g</I> is sufficiently small, evaluating a polynomial approximation is a waste of time. It also runs the risk of generating an underflow when computing the squared  argument <I>g</I><I> * </I><I>g</I> if the reduced angle is <I>really</I> small. Here, "sufficiently small" occurs when <I>g</I><I> * </I><I>g</I> is less than <I>DBL_EPSILON</I>, defined in <I>&lt;float.h&gt;</I>. Note the use of the double constant _<I>Rteps._D</I> to speed this test. (I described_<I>Rteps</I> last month.)<P>
The function _<I>Sin</I> uses _<I>Poly</I> to evaluate a polynomial by Horner's Rule. It's a simple function, so I won't bother to show it here.<P>
<h4><FONT COLOR="#000080"><A name="01FD_0103">Functions <B><I>exp</I></B> And Friends<A name="01FD_0103"></FONT></h4></P>
Another group of functions consists of <I>exp, cosh</I>, and <I>sinh</I>. In principle, you can write the latter two in terms of the first. That leads to all sorts of nasty intermediate overflows, however. What you want instead for these is a function that computes 0.5*e<I>x</I> safely. Thus, I introduced the function <I>_Exp (x, n)</I>. It computes 2<I>n</I><I>*</I>e<I>x</I> for <I>x</I> zero or finite. Scaling safely by a power of two is easy given _<I>Dscale</I>.<P>
<A href="list3.htm">Listing 3</a>
shows the function <I>exp</I>. All it has to do is check for the special IEEE 754 codes, then call _<I>Exp</I>. I don't have space to show you <I>cosh</I>, but it's only a bit more complicated. <I>sinh</I> is more complex still because you have to use a special approximation for small arguments.<P>
<A href="list4.htm">Listing 4</a>
shows _<I>Exp</I>. The header "<I>xmath.h</I>" defines the macro <I>HUGE_EXP</I> as the carefully contrived value:<P>
<pre>#define HUGE_EXP (int)(_DMAX * 900L / 1000)</pre>
This value is large enough to cause certain overflow on all known floating-point representations. It is also small enough not to cause integer overflow in the computations that follow. Thus, <I>HUGE_EXP</I> offers a coarse filter for truly silly arguments to _<I>Exp</I>.<P>
The trick here is to divide <I>x</I> by <I>ln</I>(2) and raise 2 to that power. You can pick off the integer part and compute 2<I>g</I>, for <I>g</I> in the interval [-0.5, 0.5]. You add in the integer part (plus <I>eoff</I>) at the end with <I>_Dscale</I>. That function also handles any overflow or underflow safely.<P>
Reducing the argument this way has many of the same problems as reducing the arguments to _<I>Sin</I> described above. The one advantage here is that you can choose extended-precision constants <I>c1</I> and <I>c2</I> to represent 1/<I>ln</I>(2) adequately for all reasonable argument values.<P>
As usual, the reduced argument is compared against _<I>Rteps._D</I> to avoid underflow and unnecessary computation. The ratio of polynomials approximation is taken from Cody and Waite. The approximation actually computes 2<I>g</I>/2, thus the correction to <I>xexp</I>.<P>
<h4><FONT COLOR="#000080"><A name="01FD_0104">Summary<A name="01FD_0104"></FONT></h4></P>
That should give you a taste of what it's like to write portable and accurate math functions for Standard C. These functions indeed lose no more than two bits of precision in all the tests they have undergone to date. As I warned you earlier, however, you must bring to bear quite a lot of machinery from numerical analysis to do a proper job. I didn't hesitate to rely on several references by people much more expert than I on this arcane topic.<P>
The lesson I hope to convey is that the actual computation of each math function doesn't take all that much code. (The nastiest is <I>pow</I> whose special cases puff it up to over a hundred lines.) The code must be carefully contrived, to be sure, but it is reasonably straightforward. Where the complexity comes in is handling all the error cases properly. IEEE 754 may have made floating-point arithmetic more robust, but it has certainly made this aspect of programming much harder. <P>

<h4><a href="../../../source/1991/sep91/plauger.zip">Get Article Source Code</a></h4>

</BLOCKQUOTE>
</BODY>
</HTML>



<HTML>
<HEAD>

<TITLE>November 1995/Image Processing in C, Part 15: Basic Texture Operations</TITLE></HEAD>
<body bgcolor="#ffffff">
<H2><A HREF="../tocnov.htm"><IMG SRC="../../toc.gif" ALT="{back to toc}" WIDTH="54" HEIGHT="54"></A><FONT COLOR="#FF0000">   Features</FONT></H2>

<hr><h2 align="center"><font color="#800000">Image Processing in C, Part 15: Basic Texture Operations<A name="0187_00EB"><A name="0187_00EB"></font></h2><P>
<h3 align="center"><font color="#800000"><A name="0187_0000"><A name="0187_0000">Dwayne Phillips</font></h3><hr><blockquote><P>
<P><i><A name="0187_0000"><A name="0187_0000">Dwayne Phillips works as a computer and electronics engineer with the U.S. Department of Defense. He has a PhD in Electrical and Computer Engineering from Louisiana State University. His interest include computer vision, artificial intelligence, software engineering, and programming language.</i></P><P>
<h4><FONT COLOR="#000080"><A name="0187_00EC">Introduction to the Series of Articles<A name="0187_00EC"></FONT></h4></P>
This is the 15th in a series of articles on image processing using the C Image Processing System (CIPS). Previous articles discussed reading, writing, displaying, and printing images (TIFF format), histograms, edge detection, spatial frequency filtering, sundry image operations, image segmentation, working with shapes, geometric operations, warping, and morphing. (For a more detailed discussion of the series, see the sidebar <a href="sidebar1.htm">"Navigating the Phillips Series,"</a> <I>CUJ</I>, November 1994, pp. 54-55.)This article discusses textures and some basic texture operations.<P>
<h4><FONT COLOR="#000080"><A name="0187_00ED">Discovering Texture<A name="0187_00ED"></FONT></h4></P>
Most of us have an intuitive understanding of texture but would be hard-pressed to supply a mathematical description. That doesn't stop us from using texture, humans distinguish many objects in images by their textures. For example, tree leaves and roof shingles may display similar gray levels in an image, but we can distinguish them because they have different textures.<P>
One way to describe texture is as <I>things</I> arranged in a <I>pattern</I>. Textures are a function of things and patterns &#151; mathematically, texture = f(thing, pattern). The <I>thing</I> is a grouping of pixels, such as a dot or line. The<I> pattern</I> is the arrangement of those things in random or regular positions within an image. Regular patterns are typically manmade while random patterns are natural.<P>
The ultimate objective of this conceptual wrangling is <I>pattern recognition</I>. We would like to have an operator that can characterize the things and patterns comprising a texture, so that regions of different textures can be identified by computer. Such an operator would represent a region's texture by a number, just as gray levels represent the lightness or darkness of objects. A program could then incorporate the gray-level and edge-based segmentation techniques discussed in earlier installments of this series <a href="#1">[1]</a> <a href="#2">[2]</a> to identify regions by texture. Unfortunately, a simple operator that works for all possible textures does not exist. Rather, we must choose from among a collection of operators, all of which work in some cases, some better than others. Edge detectors and difference operators work well in certain limited situations. The common sense comparison approach works well in many kinds of images, but can only isolate one texture per image. Finally, the Hurst operator <a href="#3">[3]</a> produces good results in many images, but carries a high computational cost.<P>
(This is the downside of texture operators. They are typically inefficent. Some texture operators require numerous and complicated floating point calculations. I have tried to avoid using such operators in CIPS because they take too much time on my 10MHz 286.)<P>
In this article I describe several wellknown texture operators. Due to space constraints I cannot show the code for all of these operators, though I have implemented most of them in CIPS and have provided them on this month's code disk. The operators range from simple to elaborate, common sense to ingenious. As with most kinds of image processing techniques, you will have to experiment to find out which ones work best in your application.<P>
<h4><FONT COLOR="#000080"><A name="0187_00EE">Edge Detectors as Texture Operators<A name="0187_00EE"></FONT></h4></P>
Edge detectors often work well as texture operators. This is because a textured area has many "edges" compared with an untextured area. Applying an edge detector to a texture produces many strong, bright edges while edge-detecting an untextured area yields nothing. Smoothing the edge-detected result produces corresponding bright and dark areas that are easily separated.<P>
The range operator <a href="#1">[1]</a> is a fairly simple edge detector. It sorts the pixels in an <I>n x n</I> window (by value), and replaces the center pixel with the range &#151; the largest pixel value minus the smallest.<P>
<A href="photo1.htm">Photograph 1</a>
shows an example of the range operator applied to a texture. The upper left quarter is the input image, with a small section of tightly woven texture embedded in a "carpet" texture. Note that both textures are at similar gray levels. The upper right quarter of <A href="photo1.htm">Photograph 1</a>
shows the output of a 3x3 range operator. The lower right quarter shows the result of histogram equalization <a href="#4">[4]</a> applied to the upper right quarter. Histogram equalization is not necessary for segmentation, but it does help highlight the result. Finally, the lower left quarter shows a segmentation of the range output using simple threshold segmentation. (Segmentation refers to a process by which portions of an image are classified as belonging to particular regions, or segments. For more information see <a href="#2">[2]</a>.)<P>
The variance, sigma, and skewness operators are three mathematically related edge detectors, in that each is based on the standard deviation. Variance, presented in <a href="#1">[1]</a>, uses the definition given by Russ <a href="#3">[3]</a>. Russ's definition of variance considers an <I>n x n</I> area, sums the squares of the center pixel minus each neighbor, and computes the square root of this sum (see <A href="sidebar2.htm">Equation (1)</a>)
. If the center pixel differs from its neighbors, this variance will produce a large number &#151; thus, variance will detect edges and produce many edges in a textured area.<P>
A different, and more classical definition of variance is found in Levine <a href="#8">[8]</a> and is shown in <A href="sidebar2.htm">equation (2)</a>.
 This definition requires two passes through each <I>n x n</I> window. The first pass calculates the mean or average pixel value of the window. The second pass calculates the variance. Naturally, this operation takes more time than the variance defined in <A href="sidebar2.htm">equation (1)</a>.
<P>
The sigma operator builds upon previous calculations. After calculating the variance from <A href="sidebar2.htm">equation (2)</a>,
 taking the square root produces sigma, as shown in <A href="sidebar2.htm">equation (3)</a>.
 Sigma will work as a texture operator and will also be important in calculating the skewness measure (see below). The sigma subroutine is provided on this month's code disk.<P>
<A href="photo2.htm">Photograph 2</a>
shows an example of the sigma operator applied to a texture. As in <A href="photo1.htm">photograph 1</a>,
 the upper left quarter is the input, and the upper right quarter is the output. The sigma is almost the square root of variance, so its pixel values are much smaller and darker. Though it appears completely dark, this output image contains meaningful data. Histogram equalization saves the day, retrieving this data from the "mud." The result appears in the lower right quarter. In this case histogram equalization would be absolutely necessary before attempting segmentation. The result appears in the lower left quarter.<P>
The final related edge detector is skewness <a href="#8">[8]</a>. <A href="sidebar2.htm">Equation (4)</a>
shows the formula for skewness. Skewness is very similar to variance, but it uses the cube of pixel differences rather than the square. Skewness also requires two passes through each window, once to find the mean and then once to calculate both the sigma (based on variance) and the cubes. Skewness measures the degree of symmetry in the image's histogram to determine if outlying points in the histogram favor one side or the other. If the histogram is symmetrical, skewness returns a low number. If the histogram favors one side, (i.e., is "skewed"), skewness returns a larger number. The skewness subroutine is also included on this month's code disk.<P>
<A href="photo3.htm">Photograph 3</a>
shows some effects of the skewness operator. The left half (input) shows two synthetic textures. I created the far left texture by setting each pixel to a random number from the C rand function. The next input texture is a small checkerboard pattern. The two sections on the right half are the results of the skewness operator. In this case, the far right result is all zeros, just as it appears. Since the checkerboard pattern had a perfectly symmetrical histogram, skewness returned zero everywhere. The histogram of the random pattern was also mostly symmetrical, but was skewed enough to return many non-zero values. It is easy to segment the right half of the photograph.<P>
Not all edge detectors work well with textures. <A href="photo4.htm">Photograph 4</a>
illustrates how the Sobel edge detector <a href="#4">[4]</a> failed to distinguish two textures. The upper left quarter of the photograph contains a tightly woven texture. The upper right quarter contains a random grass texture. Beneath each texture is the result of the Sobel edge detector. It did detect all the edges in the two distinctly different textures. The result, however, is not two areas with different gray levels.<P>
<h4><FONT COLOR="#000080"><A name="0187_00EF">Almost-Edge Detectors<A name="0187_00EF"></FONT></h4></P>
The difference operator <a href="#8">[8]</a>, is similar to edge detectors and can be useful in distinguishing textures. As <A href="sidebar2.htm">equation (5)</a>
shows, the difference operator merely computes the difference between a pixel and another pixel a given distance away. The difference operator works well if the chosen distance matches the pattern size of one of the textures. If the distance matches pattern size, the result is small numbers while other textures return larger numbers. The difference operator runs much faster than the variance, sigma, and skewness operators shown above and is quite effective on certain images.<P>
<A href="list1.htm">Listing 1</a>
shows the two subroutines that implement the difference operator. The subroutine adifference handles image files and disk I/O while subroutine difference-array performs the math. adifference creates an output file if required, reads the input file, calls difference-array to perform the math, and writes the output to disk. difference-array loops through the image array and calculates the difference as stated in <A href="sidebar2.htm">equation (5)</a>.
 Using adifference, it is easy to vary the size parameter to look for the size of a given texture.<P>
<A href="photo5.htm">Photograph 5</a>
shows the results of the difference operator applied to two distinct textures. The upper left quarter is the tightly woven texture shown earlier. The upper right quarter is a loose straw texture. The two lower quarters are the respective outputs. The lower left quarter appears brighter because the texture has greater differences in it than the straw texture. The difference operator successfuly distinguished between these textures.<P>
A variation of the difference operator is the mean operator <a href="#8">[8]</a>. The mean operator smoothes the output from the difference operator, replacing each pixel by the mean (or average) of the pixels in an <I>n x n</I> area. <A href="sidebar2.htm">Equation (6)</a>
describes the mean operator.<P>
<A href="list2.htm">Listing 2</a>
shows the amean subroutine. amean creates the output file if needed, reads the input file, and calls difference-array (<A href="list1.htm">listing 1</a>)
 to calculate the differences in the input image. amean then smoothes the difference array.<P>
<A href="photo6.htm">Photograph 6</a>
shows the result of the mean operator applied to the same textures processed by the difference operator in <A href="photo5.htm">photograph 5</a>.
 Note how the lower left quarter of <A href="photo6.htm">photograph 6</a>
is fuzzier than the corresponding quarter of <A href="photo5.htm">photograph 5</a>.
 This is to be expected because the mean is a smoothing operation. The two quarters in the lower half of <A href="photo6.htm">photograph 6</a>
are easily distinguished by their gray levels.<P>
<h4><FONT COLOR="#000080"><A name="0187_00F0">The Compare Operator<A name="0187_00F0"></FONT></h4></P>
The compare texture operator uses the common sense approach of comparing one texture in the image against all textures. It selects a small image area containing one sample texture (such as the brick texture in left half of <A href="photo9.htm">photograph 9</a>)
, and moves this sample texture throughout the entire image. At each sample position with respect to the image, compare subtracts the underlying image from the sample, pixel by pixel. If the image texture is similar to the sample's, the output will be small. If the image texture is different, the output will be large.<P>
<A href="photo7.htm">Photograph 7</a>
demonstrates the compare operator's effects. The upper left quarter shows the input image, comprising two textures, tightly woven and straw. The upper right quarter shows the results of sliding a 3x3 area of the woven texture across the entire input image. Once again, the results seem rather discouraging until histogram equalization is performed (output in lower right quandrant). Now the straw area produces a brighter output, and the image is easily segmented (lower left quarter). The compare function is provided on this month's code disk.<P>
<h4><FONT COLOR="#000080"><A name="0187_00F1">The Hurst Operator<A name="0187_00F1"></FONT></h4></P>
Finally, an excellent, but computationally expensive texture operator is the Hurst operator <a href="#3">[3]</a>. The Hurst operator determines a texture value for each image region by plotting pixel values against distance from the center pixel. Hurst fits this plot to a straight line, and uses the slope of that line as a measure of the texture. (This operator takes a while &#151; 15 minutes for a 100x100 area on my 10MHz 286.)<P>
The Hurst operator uses a rather interesting method for generating x,y coordinates. Recall that the range operator discussed earlier produced one range describing an entire area. The Hurst operator produces several ranges, <I>n</I> ranges for an <I>n x n</I> area. Specifically, Hurst calculates pixel value ranges for each group of pixels that are of an equal distance from the center pixel. <A href="fig1.htm">Figure 1</a>
shows three sample windows (other examples include 9x9, 11x11, etc.). In each of the sample windows, all pixels labeled with the same letter are the same distance from the center pixel. For example, in the 7x7 area at the bottom, pixel label 'a' is in the center, pixels 'b' are all one pixel away from the center, pixels 'c' are 2 pixels from the center, and so on. The Hurst operator calculates value ranges for each of the pixel distance groups 'b' through 'g'.<P>
<A href="fig2.htm">Figure 2</a>
and <A href="tab1.htm">Table 1</a>
illustrate the range calculation process. In <A href="fig2.htm">Figure 2</a>,
 two sample image sections display very different textures; image section 1 is smooth while image section 2 is rough. The range calculation results appear in <A href="tab1.htm">Table 1</a>.
 If you examine all of the pixels in image section 1 that are one pixel away from the center 'b' pixels, you will see that the largest value is 115, the and smallest is 110. This yields a range of 5. All the range values in the tables were calculated in this manner.<P>
The Hurst operator's final task is to plot the distance and range values and find the slope of the line. Hurst uses the natural logarithm of the distances on the vertical axis and the natural log of the ranges on the horizontal axis, and fits these points to a straight line. The slope of the line is the answer. The notes in <A href="tab1.htm">Table 1</a>
state that image section 1's Hurst plot had a slope of 0.99 and image section 2's had a slope of 2.0. Hurst multiplies these values by a scaling factor of 64 to produce two different gray levels representing two different textures.<P>
<A href="list3.htm">Listing 3</a>
shows a C implementation of the Hurst operator. The hurst function will work for the 3x3, 5x5, and 7x7 cases shown in <A href="fig1.htm">Figure 1</a>.
 The first section of code sets the x array to the natural logarithm of the distances. Next, hurst creates the output file if needed and reads the input file before looping through the input data. The bulk of the loop finds the ranges of pixel values for each of the pixel classes mentioned earlier. Each section of code puts the proper pixels into the elements array, sorts this array by calling sort_elements, and puts the range in the prange variable. (sort_elements was shown in an earlier installment of this series and is repeated at the bottom of <A href="list3.htm">listing 3</a>.
) hurst fits the data to a straight line by calling the fit routine. The last step sets the output image to the slope of the line scaled by 64. fit is a general purpose routine that fits data to a straight line. I took it from chapter 14 of <I>Numerical Recipes in C</I> <a href="#7">[7]</a>.<P>
<A href="photo8.htm">Photograph 8</a>
shows the result of applying the Hurst operator to the same textures used in <A href="photo1.htm">Photograph 1</a>.
 The upper left quarter is the input image and the upper right quarter is the output. The lower right is the result of smoothing the Hurst output with a low-pass filter. Smoothing blurs the result and makes segmentation easier. The lower left quarter is the final segmentation result.<P>
<A href="photo9.htm">Photograph 9</a>
shows an attempt at using the Hurst operator on a house image. The left half contains several distinct textures such as trees, roof shingles, and bricks. The right half shows that in this particular case Hurst looks like an edge detector and fails miserably as a texture segmentation operator. This only goes to show that even the best operator won't work for every conceivable image.<P>
<h4><FONT COLOR="#000080"><A name="0187_00F2">Code<A name="0187_00F2"></FONT></h4></P>
Full source code for this installment is available on this month's code disk, as well as from the online sources and ftp sites listed on page 3. To order the code disk, call Miller Freeman at +1-913-841-1631, or send e-mail to cujsub@rdpub.com.<P>
<h4><FONT COLOR="#000080"><A name="0187_00F3">Summary<A name="0187_00F3"></FONT></h4></P>
This installment of the series introduced the concept of texture and presented several operators that help distinguish between textures. Since we have not developed a universal mathematical description for texture, it's no surprise that all of our texture operators have limitations. None are universally applicable. The operators presented here will all work well with certain types of images. Experiment with them and experiment with the other pre-processing and post-processing operators from the series. Experimentation will show which types of operator to apply to a given type of image.<P>
<h4>References:</FONT></h4></P>
<a name="1"></a>[1]     Dwayne Phillips. "Image Processing, Part 10: Image Segmentation Using Region Growing and Edges," <I>The C Users Journal</I>, June: 1993, pp. 67-88.<P>
<a name="2"></a>[2]     Dwayne Phillips. "Image Processing, Part 9: Histogram-Based Image Segmentation," <I>The C Users Journal</I>, February: 1993, pp. 63-88.<P>
<a name="3"></a>[3]     John C. Russ. <I>The Image Processing Handbook</I> (CRC Press, 1992), ISBN 08493-4233-3.<P>
<a name="4"></a>[4]     Dwayne Phillips. "Image Processing, Part 5: Writing Images to Files and Basic Edge Detection," <I>The C Users Journal</I>, November: 1991, pp. 75-102.<P>
<a name="5"></a>[5]     Dwayne Phillips. "Image Processing, Part 4: Histograms and Histogram Equalization," <I>The C Users Journal</I>, August: 1991, pp. 59-70.<P>
<a name="6"></a>[6]     Dwayne Phillips. "Book Review of 'Numerical Recipes in C,'" <I>The C Users Journal</I>, December: 1990, pp. 103-105.<P>
<a name="7"></a>[7]     William H. Press, Brian P. Flannery, Saul A. Teukolsky, William T. Vetterling. <I>Numerical Recipes in C</I> (Cambridge University Press, 1988).<P>
<a name="8"></a>[8]     Martin D. Levine. <I>Vision in Man and Machine</I> (Mcgraw-Hill, 1985), ISBN 007-037446-5.<P>

<h4><a href="../../../source/1995/nov95/phillips.zip">Get Article Source Code</a></h4>

</BLOCKQUOTE>
</BODY>
</HTML>

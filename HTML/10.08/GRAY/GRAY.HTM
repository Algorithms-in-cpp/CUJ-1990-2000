


<HTML>
<HEAD>

<TITLE>August 1992/Interpreting Touchscreen Touches</TITLE></HEAD>
<body bgcolor="#ffffff">
<H2><A HREF="../tocaug.htm"><IMG SRC="../../toc.gif" ALT="{back to toc}" WIDTH="54" HEIGHT="54"></A><FONT COLOR="#FF0000">   Features</FONT></H2>

<hr><h2 align="center"><font color="#800000">Interpreting Touchscreen Touches<A name="0190_00C4"><A name="0190_00C4"></font></h2><P>
<h3 align="center"><font color="#800000"><A name="0190_0000"><A name="0190_0000">W. Harvey Gray</font></h3><hr><blockquote><P>
<P><i><A name="0190_0000"><A name="0190_0000">W. Harvey Gray is a manager in the Computing and Telecommunications Department of Martin Marietta Energy Systems in Oak<I></I> <I></I>Ridge, Tennessee. He has a Ph.D. in Mechanical Engineering from Vanderbilt University in the area of finite element methods. His<I></I> <I></I>fascination 25 years ago with Vanderbilt's first CalComp pen plotter turned into a career interest in computer graphics which, when<I></I> <I></I>coupled with finite element methods, led him to become an expert in Computer-Aided Engineering.</i></P><P>
Some consider a touchscreen to be the ultimate in userfriendly input devices. When a user touches a touchscreen, typically with his finger or other blunt pointing instrument, resistive surface coatings produce voltages that vary in magnitude, depending upon the position of the touch. An analog-to-digital converter electronically interprets these voltages into touchscreen (<I>x, y</I>) coordinate pairs. A programmer can retrieve the touch's coordinates by using calls to the touchscreen driver program.<P>
During development of a touchscreen software application for use with a projection panel, I discovered that I needed to distinguish between two fundamental types of user touches. I call them the "John Madden" touch and the button-type touch. With a "John Madden" touch, a user wants to draw or trace a line across the surface of the touchscreen like John does on TV when diagramming football plays on Sunday afternoon. Alternatively, with a button-type touch, a user wants to activate or deactivate a software function.<P>
I searched the software library that came with my touchscreen's driver program and could not find a function that detects differences between these two types of touches. So, I wrote a function that does. This article explains the algorithm I use to interpret the two touch types and presents a C module that implements the concept. It also discusses a simple example program to test the C module.<P>
<h4><FONT COLOR="#000080"><A name="0190_00C5">Requirements for a Touchscreen Presentation<A name="0190_00C5"></FONT></h4></P>
When using a touchscreen in a presentation, the software should be able to transfer the imaginary lines traced by your finger into the image displayed by a PC or overhead projector. For example, Interactive Presentation Systems (IPS), Inc. sells a product called a TAP Screen (IPS, 1991). It is a combination of Elographics, Inc. hardware and custom software (Elographics, 1989) that permits a lecturer to control an interactive presentation from a touchscreen mounted directly on top of an overhead projection panel. John Madden's performance during Super Bowl XXVI resembles the results you get with this product. Using an electronic stylus to draw into our TV image, John diagrammed plays, drew boxes around interesting people in the audience, circled cheerleaders, and even outlined the guide-wires tethering the end-zone blimp. With a TAP screen, instead of drawing into a network-broadcast video image, you draw into the image on a PC monitor. Software transfers the imaginary lines traced by your finger on the touch screen into the image on the PC screen. The overhead projector displays the composite image.<P>
In addition to displaying lines, you should be able to control the presentation from the touchscreen. If the lights in the room have been dimmed or if the PC is distant from the overhead projector you may have trouble using the keyboard. To control the presentation from the touchscreen, you must be (touchscreen touches that trace lines) and button-type touches (touches that control or switch between functions). For example, button touches might command presentation software to zoom in on a region of interest on the displayed image, to save an image after it has been drawn into and modified, or to return an image to its original, unmodified state.<P>
<h4><FONT COLOR="#000080"><A name="0190_00C6">Touchscreen Devices<A name="0190_00C6"></FONT></h4></P>
A touchscreen consists of two, thin sheets of plastic, each with a transparent, conductive coating on the facing surfaces. Sandwiched between the two sheets (and creating a uniform gap) are tiny transparent, separator dots which are evenly distributed across the active touch area. These two sheets are mounted on a thicker plastic (or glass) support surface to maintain stability. Finger pressure causes the top conductive sheet to make contact with the lower conductive sheet during the touch. The touchscreen controller measures the voltage gradients generated by the touch's contact and electronically interprets them into a finite number of (<I>x</I><I><SUB>t</SUB></I><I>, y</I><I><SUB>t</SUB></I>) touchscreen coordinate pairs.<P>
Touchscreen controllers may be mounted either in a separate box and accessed via a PC's RS232 port, or located on a circuit board that inserts directly into the PC's bus. Bus type controllers interpret and return touch points at a greater rate than RS232 type controllers, other things being equal.<P>
<h4><FONT COLOR="#000080"><A name="0190_00C7">A Touchscreen Driver<A name="0190_00C7"></FONT></h4></P>
I worked with the Elographics, Inc. MS-DOS Terminate and Stay Resident (TSR) driver program, called ELODEV, for this project. Passing the appropriate command-line arguments to ELODEV during installation configures the system for the correct combination of touchscreen and controller. With my touchscreen and PC configuration, ELODEV takes less than 7KB of memory.<P>
An application program and the ELODEV TSR communicate through a user-programmable software interrupt. Multiple copies of the ELODEV TSR can be present to control multiple touchscreens and, when not in use, individual copies can be removed from memory. ELODEV responds to 26 different commands and, because it is a TSR, can be called easily from C. Its C interface provides the following interrupt functions:<P>
<UL><li><I>driverinfo</I> - returns touchscreen hardware and status information</li>
<li><I>opentouch</I> - prepares the touchscreen for use</li>
<li><I>closetouch</I> - terminates touchscreen use</li>
<li><I>enabletouch</I> - enables touchscreen interrupts</li>
<li><I>disabletouch</I> - disables touchscreen interrupts</li>
<li><I>setcalibrange</I> - calibrates the touchscreen</li>
<li><I>gettouch</I> - returns touch-point coordinate values</li></UL>
Elographics, Inc. provides language bindings for ELODEV's functions in a variety of languages including several C dialects. Their <I>#include file, dvrfunc.h</I>, defines the functional interface between a touchscreen software application and their interrupt handler. This file contains a <I>#define</I> macro for each of the 26 touchscreen functions. These macros expand into the appropriate calls to their interrupt handler. Compiling and linking their source (<I>dvrfunc.c</I>) with your application, satisfies the external reference for their interrupt handler and produces a touchscreen-aware executable program.<P>
Of the 26 functions to which the ELODEV TSR responds, only one, <I>gettouch</I>, returns touch-point coordinates. This function takes three arguments, <I>xt, yt</I>, and <I>ut. xt</I> and <I>yt</I> are pointers to <I>ints</I> and return a touch-point coordinate (<I>x</I><I><SUB>t</SUB></I><I>, y</I><I><SUB>t</SUB></I>). <I>ut</I> is a pointer to a <I>boolean</I> and returns the untouch logical value. If <I>ut</I> is <I>TRUE</I>, then the user removed a finger from the touchscreen, making the area the finger vacated the last touch point for the current touch. <I>gettouch</I> also returns a boolean value. If <I>TRUE</I>, then a touch was present. If <I>FALSE</I>, then a touch was not present. (The ELODEV C interface <I>typedefs</I> <I>boolean</I> to be an <I>unsigned char</I>.)<P>
<h4><FONT COLOR="#000080"><A name="0190_00C8">Touchscreen Touches<A name="0190_00C8"></FONT></h4></P>
A touchscreen touch consists of many touch-point (<I>x</I><I><SUB>t</SUB></I><I>, y</I><I><SUB>t</SUB></I>) coordinate values. Theoretically, a touch consists of an infinite number of touch points. However, the speed of a PC and touchscreen hardware and their configuration will dictate the actual (finite) number of touch points returned during a touch. In practice, my experience has been that Elographics, Inc. PC bus controllers return enough touch points to insure smooth, visually-satisfying lines at VGA resolutions while finger or stylus motions simulate normal-speed, cursive handwriting on a touchscreen's surface.<P>
Uncalibrated values of touch-point coordinates range from (0,0) to (4095,4095). Touches may be calibrated and translated using an ELODEV function that changes the default characteristics of the touch screen controller and software. One useful coordinate mapping scheme instructs the ELODEV TSR to return touch-point coordinates ranging from (0,0) to (639,479) (the graphics coordinate range of a PC's VGA screen) assuming that lines are to be drawn directly into the VGA image. The modules I describe in this article will work with any touchscreen calibration; however, the example program only demonstrates using a touchscreen in its native (or uncalibrated, untranslated) mode.<P>
<h4><FONT COLOR="#000080"><A name="0190_00C9">Distinguishing Touch Types<A name="0190_00C9"></FONT></h4></P>
The algorithm to distinguish between button- and curvetype touches dynamically examines a touch's touch points in the order that they are received. The algorithm determines if any touch points fall outside of an imaginary circle (of a known radius) whose center is located at the instantaneous touch centroid. All touch points within the imaginary circle's (button's) area indicates a button touch. Any touch points lying outside of a button's imaginary area returns a curve touch. Calculating the instantaneous touch centroid (<I>x</I><I><SUB>cen</SUB></I><I>, y</I><I><SUB>cen</SUB></I>) requires summing the individual touch-point coordinate values and dividing by the number of received touch points, <I>n</I>, or<P>
<IMG SRC="equat1.gif"><P>
The distance, <I>d</I><I><SUB>i</SUB></I>, between the most recent touch point (<I>x</I><I><SUB>i</SUB></I><I>, y</I><I><SUB>i</SUB></I>) and the touch centroid (<I>x</I><I><SUB>cen</SUB></I><I>, y</I><I><SUB>cen</SUB></I>) is<P>
<IMG SRC="equat2.gif"><P>
Therefore, if the touch is a button type and <I>r</I><I><SUB>b</SUB></I> is the imaginary button radius, then <I>d</I><I><SUB>i</SUB></I> &lt;= <I>r</I><I><SUB>b</SUB></I> for 1 &lt; <I>i</I><I>n</I>. If <I>d</I><I><SUB>i</SUB></I> &gt; <I>r</I><I><SUB>b</SUB></I> for any <I>i</I>, then the touch is a curve type.<P>
<h4><FONT COLOR="#000080"><A name="0190_00CA">The Implementation<A name="0190_00CA"></FONT></h4></P>
<I>GetTouch.c</I> (see <A href="list1.htm">Listing 1</a>)
 provides an enhanced and extended interface to ELODEV's <I>gettouch</I> function. Five external functions are coded in <I>GetTouch.c</I>. These five functions are <I>GetTouch, InitializeTouch, ReplayTouch, SetButtonRadius</I>, and <I>TouchInfo</I>. Not only do these functions provide all the information that ELODEV's <I>gettouch</I> function provides, but they also set and return other useful information about a touch, including whether the pending touch is a button-type touch. <A href="list2.htm">Listing 2</a>
shows module <I>GetTouch.h</I>. It contains all the external definitions needed to interface with <I>GetTouch.c</I>, including function prototypes and struct tags.<P>
<h4><FONT COLOR="#000080"><A name="0190_00CB"><I>GetTouch<A name="0190_00CB"></I></FONT></h4></P>
The function <I>GetTouch</I> is the principal interface between an application code and the ELODEV TSR. From an application's point-of-view, it replaces ELODEV's <I>gettouch. GetTouch</I> returns a pointer to a <I>touchxy struct</I>. If there is no touch present, then <I>GetTouch</I> returns a <I>NULL</I> pointer to a <I>touchyxy struct</I>; else, it returns a legitimate pointer to touchpoint data. Additionally, <I>GetTouch</I> returns the logical value of the button variable via a pointer to a <I>boolean</I>.<P>
The general design of <I>GetTouch</I> follows the rule that if the touch is a button type, then <I>d</I><I><SUB>i</SUB></I> &lt;= <I>r</I><I><SUB>b</SUB></I> for 1 &lt; <I>i</I> &lt;= <I>n</I>. This implies that every touch's touch point must be examined before a determination can be made about the touch type. Since the number of touch points for a touch cannot be known in advance, what do you do? Each touch point could be <I>malloced</I> into a simple linked list, but this solution would preclude using the function <I>GetTouch</I> in a TSR application. In practice, however, I've found that button touches are much shorter in duration than curve touches. It follows that the shorter the touch duration, the fewer the touch points. So even though the total number of touch points for a button touch is never known in advance, choosing a reasonably large static touch buffer (and carefully crafting a few explanatory words about brief button touches in any user documentation) will suffice. Changing the #<I>defined</I> value of <I>TOUCH_BUF_NUM</I> easily changes the size of <I>GetTouch.c'</I>s touch buffer.<P>
The pseudo-code in <A href="fig1.htm">Figure 1</a>
describes how the function <I>Get Touch</I> works.<P>
The function <I>GetTouch</I> uses several static functions to implement this algorithm. <I>buffer_touch</I> reads an entire touch and fills up the static <I>touchxy struct</I> that stores the internal touch point buffer. <I>store_touch</I> stores a single touch point into the touch buffer and calculates the instantaneous touch distance, <I>d</I><I><SUB>i</SUB></I>. Notice that this module uses <I>d</I><I><SUB>i</SUB></I><I><SUP>2</SUP></I> and <I>r</I><I><SUB>b</SUB></I><I><SUP>2</SUP></I> in any calculations and comparisons, thus avoiding floating-point arithmetic and its slower speed and increased memory requirements. <I>buffered</I> and <I>unbuffered</I> return pointers to <I>touchxy</I> <I>structs</I> containing buffered and unbuffered touch points, respectively.<P>
<h4><FONT COLOR="#000080"><A name="0190_00CC">Other <B><I>Get touch.c</I></B> Functions<A name="0190_00CC"></FONT></h4></P>
The other four globally-scoped functions of <I>GetTouch.c</I> either set parameters for, modify the behavior of, or return information about function <I>GetTouch</I>. <I>InitializeTouch</I> initializes several of the static variables in <I>GetTouch.c.</I> Call it once before calling any of the other functions.<P>
<I>SetButtonRadius</I>, appropriately, sets the button radius, <I>r</I><I>b</I>. It takes one argument, the value of the button radius (in appropriate units). I've found that between 4% to 8% of the diagonal dimension of the touchscreen's touch area is a reasonable range for button radii. For example,<P>
<IMG SRC="equat3.gif"><P>
where (<I>x</I><I><SUB>min</SUB></I><I>, y</I><I><SUB>min</SUB></I>) and (<I>x</I><I><SUB>max</SUB></I><I>, y</I><I><SUB>max</SUB></I>) are the current touchscreen minimum and maximum calibrated and translated coordinate values.<P>
<I>ReplayTouch</I> does what its name implies, but only works if <I>GetTouch.c's</I> internal touch buffer holds an entire touch. If not, then nothing happens. If it does hold a complete touch, then a subsequent call to <I>GetTouch</I> will replay it. <I>ReplayTouch</I> accepts an argument that overrides the button-type logical value for the touch. The typical use for this function occurs if a user dots an 'i' while writing on the touchscreen. Since <I>GetTouch</I> normally interprets the dot of an 'i' to be a button touch, <I>ReplayTouch</I> permits overriding this default behavior and drawing a dot on the 'i'.<P>
Lastly, <I>TouchInfo</I> returns a pointer to a <I>touchit struct</I> that contains the values of the touch point (<I>X</I><I><SUB>cen</SUB></I><I>, y</I><I><SUB>cen</SUB></I>) centroid, the number of touch points, and the button-type indicator.<P>
<h4><FONT COLOR="#000080"><A name="0190_00CD">Testing the Software<A name="0190_00CD"></FONT></h4></P>
<A href="list3.htm">Listing 3</a>
contains a simple program, called <I>ShowTch.c</I>, that demonstrates the use of and tests module <I>GetTouch.c.</I> This program repetitively reads, examines, and reports on touch types and statistics until a keyboard key press. The first part of <I>main</I> is typical of many touchscreen applications. It begins by finding the ELODEV driver and software interrupt number with a call to <I>finddriver. driverinfo</I> returns driver information so <I>ShowTch.c</I> can make sure that the version of the ELODEV TSR matches the version of the Elographics, Inc. functions linked with this application. <I>setmode</I> selects <I>BUFFERED, UNTOUCH,</I> and <I>STREAM</I> touchscreen operational characteristics. (<I>UNTOUCH</I> and <I>STREAM</I> touchscreen modes must be set for <I>Get Touch.c</I> to work correctly.) Finally, standard ELODEV functions open and enable the touchscreen for use.<P>
<I>ShowTch.c</I> initializes <I>GetTouch.c</I> by calling <I>InitializeTouch</I> and <I>SetButtonRadius</I>. The value of the argument passed to <I>SetButtonRadius</I> is <I>r</I><I>b</I>. This program uses 4% (4096/25) of the uncalibrated touchscreen coordinate maximum value, but you can easily adjust it to suit your own needs. The next part of <I>ShowTch.c</I> is a while loop that examines and prints touches by repetitively calling <I>touch_loop</I>. The program continues until a keyboard key press, then finishes by flushing the keyboard buffer and closing the touchscreen.<P>
<I>touch_loop</I> loops through all a touch's touch points. (A touch is present when the pointer to a <I>touchxy struct</I> returned by <I>GetTouch</I> is not <I>NULL</I>.) If a touchscreen touch is not present, <I>touch_loop</I> simply returns. When one is present, <I>touch_loop</I> eats all the touch-point coordinates until an untouch occurs. Upon receiving an untouch, <I>touch_loop</I> calls <I>print_touch</I> to print out the touch information. Control returns to <I>main</I> and the process starts over again. <A href="list4.htm">Listing 4</a>
contains a makefile for <I>ShowTch.c.</I><P>
<h4>References</FONT></h4></P>
Elographics, Inc. 1989. <I>ELODEV Touchscreen Driver Program Version 1.4 - Installation Guide and Programmer's Reference Manual</I>, Version 2.0b. Oak Ridge, TN.<P>
Interactive Presentation Systems. 1991. <I>TAP Screen Users Manual</I>, Version PC1.0. Oak Ridge, Tennessee.<P>

<h4><a href="../../../source/1992/aug92/gray.zip">Get Article Source Code</a></h4>

</BLOCKQUOTE>
</BODY>
</HTML>

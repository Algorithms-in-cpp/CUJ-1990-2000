


<HTML>
<HEAD>

<TITLE>May 1991/More Accurate Linear Interpolation</TITLE></HEAD>
<body bgcolor="#ffffff">
<H2><A HREF="../tocmay.htm"><IMG SRC="../../toc.gif" ALT="{back to toc}" WIDTH="54" HEIGHT="54"></A><FONT COLOR="#FF0000">   Numerical Applications</FONT></H2>

<hr><h2 align="center"><font color="#800000">More Accurate Linear Interpolation<A name="00D5_0084"><A name="00D5_0084"></font></h2><P>
<h3 align="center"><font color="#800000"><A name="00D5_0000"><A name="00D5_0000">John Forkosh</font></h3><hr><blockquote><P>
<P><i><A name="00D5_0000"><A name="00D5_0000">John Forkosh has an MS in physics, and for the past ten years has been an independent consultant working primarily under VAX/VMS in C. He developed the algorithm discussed in this article while at the Goddard Institute for Space Studies in New York City, working on the radiative transfer code for a general circulation model of the earth's atmosphere (used to study climatic change, particularly due to increased carbon dioxide resulting from burning fossil fuels). Readers may contact him at 285 Stegman Parkway #309, Jersey City, NJ 07305.</i></P><P>
Scientific applications often require the very frequent evaluation of complicated functions. To reduce computational overhead, you can define such a function using a table of its values at various fixed points. You then need some form of interpolation to estimate values of the function at intermediate points. Linear interpolation is the quickest procedure. Unfortunately, it is also usually the least accurate.<P>
A lookup table for a function <I>f(x)</I> is a sequence of numbers <i>y<SUB>i</SUB></i><I>=f(x<SUB>i</SUB>), i=1...n.</I> Using linear interpolation, you approximate <I>f(x)</I> by straight-line segments connecting the <I>yi</I>s. Consider the simple function <I>f(x)=x</I><I><SUP>2</SUP></I>. Because this function is concave (its second derivative <I>f"(x)=2</I> is always positive) the straight line segments will always lie above the curve (i.e., linearly interpolated values will always be too large).<P>
You can avoid such systematic errors by using line segments connecting a sequence of "pseudo-values" <i>y<SUB>i</SUB></i><I>*</I> that you determine by minimizing the sum of the integrated square-errors attributable to each segment. A least-squares technique determines the appropriate <i>y<SUB>i</SUB></i><I>*</I>s. The result is that the table does not contain exact values for the function <I>f(x)</I> at the points <I>x</I><I>i</I>. However, it minimizes the mean-square error due to sampling random points in the function's domain. For instance, for <I>f(x)=x</I><I><SUP>2</SUP></I> in the interval <I>-10&lt;=x&lt;=10</I> with table values at each integer, the mean square error is reduced by a factor of 6 (the rms error by a factor of 2.45).<P>
This discussion is pitched at about the level of <I>Numerical Recipes in C</I> (Cambridge University Press, 1988). It illustrates not only interpolation (Chapter 3), but also least squares (Chapter 14) and the solution of linear algebraic equations (Chapter 2). The latter arises because, for a table with <I>n</I> values, our analysis expresses the <I>y<SUB>i</SUB>*</I>s as <I>n</I> simultaneous equations in terms of the <i>y<SUB>i</SUB></i>s. This article provides complete code so that you can apply the algorithm to any function <I>f(x)</I> whatsoever.<P>
<h4><FONT COLOR="#000080"><A name="00D5_0085">Functions Of A Single Variable<A name="00D5_0085"></FONT></h4></P>
Interpolation techniques represent a function <I>y=f(x)</I> by a table of values <i>y<SUB>i</SUB></i><I>=f(x<SUB>i</SUB>), i=1...n</I>. Between <i>y<SUB>i</SUB></i> and <I>y<SUB>i</SUB>+1</I>, standard linear interpolation approximates <I>f(x)</I> by a line segment, which I'll denote by <I>u<SUB>i</SUB>(x)=a<SUB>i</SUB>x+b<SUB>i</SUB>, x<SUB>i</SUB>&lt;=x&lt;=x<SUB>i+1</SUB></I>, with <I>a<SUB>i</SUB></I> and <I>b<SUB>i</SUB></I> chosen so that <I>u<SUB>i</SUB>(x<SUB>i</SUB>)=y<SUB>i</SUB></I> and <I>u<SUB>i</SUB>(x<SUB>i+1</SUB>)=y<SUB>i+1</SUB></I>. This provides exact values of <I>f(x)</I> at the <I>x<SUB>i</SUB>s</I>, but it does not constrain the mean square errors:<P>
<P><A name="equat1"><b>Equation (1)</a></b><br>
<IMG SRC="equat1.gif"></P>

In addition, it gives rise to systematic errors when the sign of <I>f"(x)</I> doesn't change between points. If <I>f"&gt;0</I> (concave function) then <I>u-f&gt;0</I> for all <I>x</I> in the interval (and similarly for a convex function). This situation is illustrated in <A href="fig1a.htm">Figure 1a</a>.
<P>
<A href="fig1b.htm">Figure 1b</a>
illustrates the procedure to be developed. In this case, the line segments <I>u<SUB>i</SUB>(x)</I> connect points <I>u<SUB>i</SUB>(x<SUB>i</SUB>)=y<SUB>i*</SUB></I> and <I>u<SUB>i</SUB>(x<SUB>i+1</SUB>)=y<SUB>i+1</SUB>*</I>. The <I>y<SUB>i</SUB>*</I>s are determined by a least squares technique that minimizes the sum of the error terms given in <A href="forkosh.htm#equat1">Equation 1</a>,
 so that:<P>
<P><B><A name="equat2">Equation (2)</A></B><br>
<IMG SRC="equat2.gif"><P>

This gives <I>n</I> equations for the <I>n</I> unknown <I>y</I><I><SUB>i</SUB></I>*s.<P>
The hard work is doing all the algebra necessary to formulate these <I>n</I> equations so that you can program their solution. To keep the analysis tractable, assume that <I>x<SUB>i+1</SUB>-x<SUB>i</SUB>=</I><FONT FACE="Symbol">D</FONT><I>x</I> is constant. Then the line segments can be written as in Equation (a) (<A href="forkosh.htm#equat3">Equation 3</a>)
.</I><P>

<P><B><A name="equat3">Equation (3)</A></B><br>
<IMG SRC="equat3.gif"><P>

<A href="forkosh.htm#equat3">Equation 3</a> gives the sum of the error terms given by <A href="forkosh.htm#equat1">Equation 1</a>
and <A href="forkosh.htm#equat2">Equation 2</a>.
<P>
At the interior points <I>1&lt;i&lt;n</I>, two terms from the sum in <A href="forkosh.htm#equat3">Equation 3</a> contain subscript <I>i</I>, so that:<P>

<P><B><A name="equat4a">Equation (4a)</A></B><br>
<IMG SRC="equat4a.gif"><P>

while at the boundaries <I>i=1</I> and <I>i=n</I>, only one term contributes, so that:<P>

<P><B><A name="equat4b">Equation (4b)</A></B><br>
<IMG SRC="equat4b.gif"><P>

You can evaluate these derivatives directly. After evaluating them and making several substitutions of variables, you get:<P>

<P><B><A name="equat5a">Equation (5a)</A></B><br>
<IMG SRC="equat5a.gif" width=700><P>

<P><B><A name="equat5b">Equation (5b)</A></B><br>
<IMG SRC="equat5b.gif" width=700><P>

So far the analysis is exact. To finish the problem, approximate the right-hand integrals using Simpson's rule applied at the midpoint of each interval. Let <I>y<SUB>i</SUB>&plusmn;&frac12;=f(x&plusmn;&frac12;<FONT FACE="Symbol">D</FONT>x)</I> so that:<P>
<IMG SRC="equat.gif"><P>
from which we can evaluate:<P>

<P><B><A name="equat6a">Equation (6a)</A></B><br>
<IMG SRC="equat6a.gif"><P>

<P><B><A name="equat6b">Equation (6b)</A></B><br>
<IMG SRC="equat6b.gif"><P>

You can obtain any desired degree of accuracy by using better approximations in <A href="forkosh.htm#equat6a">Equation 6</a>. Substitute the results back into <A href="forkosh.htm#equat5a">Equation 5</a>, and in this case:<P>

<P><B><A name="equat7a">Equation (7a)</A></B><br>
<IMG SRC="equat7a.gif"><P>

<P><B><A name="equat7b">Equation (7b)</A></B><br>
<IMG SRC="equat7b.gif"><P>

<A href="forkosh.htm#equat2">Equation 2</a>,
 <A href="forkosh.htm#equat4a">Equation 4</a>, and <A href="forkosh.htm#equat7a">Equation 7</a> now let you write down <I>n</I> equations for the <I>n</I> unknown <I>y<SUB>i</SUB>*</I>s in terms of the known <I>y<SUB>i</SUB></I>s (see equation (b) in <A href="forkosh.htm#equat3">Equation 3</a>)
.<P>
These results are most easily written in matrix form:<P>

<P><B><A name="equat8">Equation (8)</A></B><br>
<IMG SRC="equat8.gif" width=700><P>

<A href="forkosh.htm#equat8">Equation 8</a>
specifies how to construct a table of <I>y</I>*s, for linearly interpolating any function <I>f(x)</I>, that minimizes (modulo Simpson's rule) the mean-square error due to randomly sampling points in the function's domain. However, <I>f(x)</I> must be a function of a single variable. The application for which this algorithm was originally designed requires interpolation of a function <I>z=f(x,y)</I> of two variables. This more general situation is conceptually quite similar to the one-dimensional case discussed. The required algebra, however, becomes noticeably more complicated. I therefore decided to stop the formal discussion of the algorithm at this point.<P>
<h4><FONT COLOR="#000080"><A name="00D5_0086">Discussion Of Code<A name="00D5_0086"></FONT></h4></P>
<A href="list1.htm">Listing 1</a>
and <A href="list2.htm">Listing 2</a>
show the implementation of <A href="forkosh.htm#equat8">Equation 8</a>.
 <A href="list1.htm">Listing 1</a>
contains a C function <I>lint1d(x0,dx,n,f,y)</I> that returns a table of <I>y</I>*s, suitable for one-dimensional linear  interpolation, as prescribed by <A href="forkosh.htm#equat8">Equation 8</a>.
 It simply <I>mallocs</I> a temporary <I>nxn</I> array in which the coefficient matrix is set up, then calls the user-supplied function <I>f</I> to initialize array <I>y</I> with the vector of constants,. Finally, it solves the simultaneous equations, returning the <I>y</I>* solutions to the caller in the same array <I>y</I>. <A href="list1.htm">Listing 1</a>
also contains a test driver for <I>lint1d.</I> Some sample output for <I>f(x)=x<SUP>2</SUP></I> as discussed in the introduction is shown in <A href="fig3.htm">Figure 3</a>.
<P>
<A href="list2.htm">Listing 2</a>
contains the simultaneous equation solver used by <I>lint1d.</I> It's a Fortran-to-C port of an old IBM Scientific Sub-routine Package routine, <I>simq</I>, as noted in the code. As you can see, <A href="forkosh.htm#equat8">Equation 8</a>
specifies a very straightforward procedure, and the resulting code for <I>lint1d</I> is correspondingly simple. The code for <I>simq</I> is a bit dense, but can be treated as a black box for the purposes of this application.<P>
By supplying the address of your own function as the argument <I>f</I> to <I>lint1d</I>, an interpolation table can very easily be constructed to suit any purpose whatsoever. Thus, almost any application that employs one-dimensional linear interpolation at fixed intervals should be able to realize noticeable improvements in accuracy, through a simple one-line call to <I>lint1d</I>. Afterwards, interpolation on the improved table is performed transparently and requires no application-level recoding.<P>
Both listings contain embedded drivers (that are compiled when the #<I>defined</I> flag <I>TESTDRIVE</I> is true) to facilitate module-evel testing and to illustrate usage. I've also tried to carefully document the code (except for some of the more elaborate indexing arithmetic required near the bottom of <I>simq</I>). My experience with scientific code is that it frequently tends to be under-documented and also under-robust. The latter problem can be particularly pernicious since the code usually won't blow up but will simply supply the wrong result due to an inappropriate numerical method or due to some more trivial problem. (For instance, I once worked on a model where the value of p had been entered incorrectly.) Because numerical results are usually not analytically verifiable, and because feedback mechanisms frequently prevent small errors from growing uncontrollably, a researcher may not realize that the results are little more than massaged noise. You can effectively guard against such difficulties by using a design that carefully decomposes a complicated calculation into easily describable functional components that can be individually tested for known correct results.<P>

<B><I>Note: Figure 2 has been replaced with Equation 3.</I></B>

<h4><a href="../../../source/1991/may91/forkosh.zip">Get Article Source Code</a></h4>

</BLOCKQUOTE>
</BODY>
</HTML>

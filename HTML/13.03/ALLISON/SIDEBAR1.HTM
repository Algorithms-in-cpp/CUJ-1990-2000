<HTML><HEAD><TITLE>March 1995/Code Capsules/Sidebar</TITLE></HEAD><BODY BACKGROUND="" BGCOLOR="#FFFFFF" TEXT="#000000">

<h3 align="center"><FONT FACE="Garamond" COLOR="#000080">Floating-point Number Systems</FONT></h3><hr>
<BLOCKQUOTE>
The computer's difficulty in manipulating real numbers has long been a source of frustration and confusion for students and practitioners alike. The program in <A href="list1.htm">Listing 1</a>
shows how a simple sequence of sums can go awry. It calculates the expression ex by the formula:<P>
<IMG SRC="equat1.gif"><P>
and compares the result to the "correct" answer given by the <I>exp</I> function in the standard library. This works correctly for positive arguments, but the result for negative arguments isn't even close! The problem, of course, is that computers, with their finite capabilities, can only represent a minuscule subset of the set of real numbers. A good chunk of numerical analysis deals with <I>roundoff error</I>, the quirks of finite-precision arithmetic.<P>
In days gone by, many computers used a <I>fixed-point</I> number system, which uses numbers derived from a given radix (<FONT FACE="Symbol" SIZE=2>b</FONT>), precision (p), and fraction size (f). For example, the values <FONT FACE="Symbol" SIZE=2>b</FONT>=10, p=4, and f=1 define the following set of 19,999 numbers:<P>
<pre><I>F = {-999.9, - 999.8,...,999.8, 999.9}</I></pre>
Since these numbers are evenly spaced, the maximum absolute error in representing any real number <I>x</I> in this system is bounded by 0.05. In other words,<P>
<pre> |<I>x-</I><I><U>fix</I></U><I>(x)</I>| <U>&lt;</U> 0.05</pre>
The set of machine integers form a fixed-point system with f=0, and a maximum absolute error of 0.5 for systems that round, and no greater than 1.0 for systems that truncate.<P>
Absolute error is not generally useful in mathematical computations, however. As is often the case, you are more often interested in percentages, or how one number differs in relation to another. You compute the <I>relative error</I> of y with respect to x by the following formula:<P>
<IMG SRC="equat2.gif"><P>
Consider how the numbers 865.54 and 0.86554 are represented in <I>F</I>:<P>
<pre>fix(865.54) = 865.5
fix(.86554) = 0.9</pre>
Because the number of decimals is fixed, the second is a much poorer fit than the first, which the relative errors illustrate:<P>
<IMG SRC="equat3.gif"><P>
The second is 1,000 times worse than the first!<P>
Nowadays computers provide <I>floating-point</I> number systems, which represent numbers in the form<P>
<pre>&plusmn;0.d<SUB>1</SUB>d<SUB>2</SUB>...d<I><SUB>p</SUB></I> X <FONT FACE="Symbol" SIZE=3>b</FONT><SUP>e</SUP></pre>
where<P>
<pre><I>m</I> <U>&lt;</U> <I>e</I> <U>&lt;</U> M, 0 <U>&lt;</U> d<SUB>i</SUB> &lt; <FONT FACE="Symbol" SIZE=3>b</FONT></pre>
This is like the <I>scientific notation</I> that you learned in school, except that in this case the base (<FONT FACE="Symbol" SIZE=2>b</FONT>) can be other than 10, and there is an upper limit on the precision (p). Most floating-point systems use a <I>normalized</I> representation, which means that d1 cannot be zero. These number systems are called floating-point for the obvious reason &#151; the radix point "floats" and the exponent (e) adjusts accordingly to preserve the correct value.<P>
Consider a floating-point system <I>G</I> defined by <FONT FACE="Symbol" SIZE=2>b</FONT>=10, p=4, m=-2, and M=3. The numbers from the fixed-point example above are represented as:<P>
<pre><I>fl</I>(8.65.54)+0.8655 x 10<SUP>3</SUP>
<I>fl</I>(865.554)=0.8655 x 10<SUP>0</SUP></pre>
Now look what happens when calculating the relative errors of the two representations:<P>
<IMG SRC="equat4.gif"><P>
<IMG SRC="equat5.gif"><P>
It can be shown that the relative error of representing any real number within the range of a floating-point system is no greater than <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>1-p</SUP>, which is 0.001 in G.<P>
Floating-point numbers are not evenly spaced. In <I>G</I>, for example, the next number greater than 1 is 1.001, a spacing of 0.001, but the next number after 10 is 10.01, which is 0.01 to the right. In general, the spacing among all numbers between powers of <FONT FACE="Symbol" SIZE=2>b</FONT>, say between <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>e</SUP> and <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>e+1</SUP>, is <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>e+1-p</SUP>. A trivial combinatorial analysis shows that each interval [<FONT FACE="Symbol" SIZE=2>b</FONT><SUP>e</SUP>, <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>e+1</SUP>] has (<FONT FACE="Symbol" SIZE=2>b</FONT>&#151;1) <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>p-1</SUP> floating-point numbers, and the total number of representable floating-point numbers in a system is 2(M&#151;m+1)(<FONT FACE="Symbol" SIZE=2>b</FONT>&#151;1)<FONT FACE="Symbol" SIZE=2>b</FONT><SUP>p-1</SUP> (so increasing p increases the density of the number system). And as shown above, although smaller numbers are closer together and larger numbers are farther apart, the relative spacing between consecutive floating-point numbers is essentially the same throughout the system. In fact, the relative spacing between two adjacent representable numbers within an interval [<FONT FACE="Symbol" SIZE=2>b</FONT><SUP>e</SUP>, <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>e+1</SUP>] is <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>1-p</SUP>, and between <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>e+1</SUP> and its immediate predecessor is <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>-p</SUP>.<P>
The quantity <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>1-p</SUP>, which also happens to be the spacing between 1.0 and its immediate successor, is called the <I>machine epsilon</I> (<FONT FACE="Symbol" SIZE=2>e</FONT>), and is a good measure of the granularity of a floating number system. The smallest floating-point magnitude other than zero is of course <FONT FACE="Symbol" SIZE=2>b</FONT>, usually denoted as <FONT FACE="Symbol" SIZE=2>s</FONT>, and the largest magnitude, <FONT FACE="Symbol" SIZE=2>l</FONT>, is <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>M</SUP>(1&#151;<FONT FACE="Symbol" SIZE=2>b</FONT><SUP>-p</SUP>).<P>
The Standard C header &lt;<I>float.h</I>&gt; provides manifest constants for all of these parameters as follows:<P>
<pre><FONT FACE="Symbol" SIZE=3>b</FONT> == FLT_RADIX
p == DBL_MANT_DIG
m == DBL_MIN_EXP
M == DBL_MAX_EXP
<FONT FACE="Symbol" SIZE=3>e</FONT> == DBL_EPSILON
<FONT FACE="Symbol" SIZE=3>s</FONT> == DBL_MIN
<FONT FACE="Symbol" SIZE=3>l</FONT> == DBL_MAX</pre>
&lt;<I>float.h</I>&gt; also provides the <I>float</I> and <I>long double</I> equivalents of the last five parameters, representing the three (not necessarily distinct) floating-point number systems in standard C (see <A href="tab4.htm">Table 4</a>)
.<P>
The program in <A href="list2.htm">Listing 2</a>
calculates a root of x<SUP>2</SUP>+x+1 in the interval [&#151;1, 1] by the method of bisection. The algorithm halves the interval (which must contain a sign change for the function <I>F</I>) until the relative spacing between the endpoints is less than or equal to machine epsilon. Such a loop may never terminate if you expect greater precision than this.<P>
Should you find yourself in an environment that does not provide the parameters in <I>&lt;float.h&gt;,</I> you can compute <FONT FACE="Symbol" SIZE=2>b</FONT>, p, and <FONT FACE="Symbol" SIZE=2>e</FONT> directly. To see how this is possible, remember that the spacing between consecutive floating-point numbers increases with the magnitude of the numbers. Eventually there is a point where the spacing between adjacent numbers is greater than 1. (In fact, the first interval where this holds true is [<FONT FACE="Symbol" SIZE=2>b</FONT><SUP>p</SUP>, <FONT FACE="Symbol" SIZE=2>b</FONT><SUP>p+1</SUP>], because the integers therein require p+1 digits in their representation.) The positive integers precisely representable in a floating-point system are these:<P>
<pre>1,2,...,<FONT FACE="Symbol" SIZE=3>b</FONT><SUP>p-1</SUP>,<FONT FACE="Symbol" SIZE=3>b</FONT><SUP>p</SUP>,<FONT FACE="Symbol" SIZE=3>b</FONT><SUP>p</SUP>+<FONT FACE="Symbol" SIZE=3>b</FONT>,<FONT FACE="Symbol" SIZE=3>b</FONT><SUP>p</SUP>+2<FONT FACE="Symbol" SIZE=3>b</FONT>,..., <FONT FACE="Symbol" SIZE=3>b</FONT><SUP>p+1</SUP>,<FONT FACE="Symbol" SIZE=3>b</FONT><SUP>p+1</SUP>+<FONT FACE="Symbol" SIZE=3>b</FONT><SUP>2</SUP>,...</pre>
To find the radix, the program in <A href="list3.htm">Listing 3</a>
keeps doubling <I>a</I> until it reaches a point where the spacing exceeds 1. It then finds the next larger floating-point number and subtracts <I>a</I> to get <FONT FACE="Symbol" SIZE=2>b</FONT>. The program then computes the smallest power of <FONT FACE="Symbol" SIZE=2>b</FONT> that will produce numbers whose adjacent spacing exceeds 1  that power is the precision p. To find <FONT FACE="Symbol" SIZE=2>e</FONT>, the program finds the nearest representable neighbor to the right of 1, and subtracts 1.<P>
</BLOCKQUOTE>
</BODY>
</HTML>

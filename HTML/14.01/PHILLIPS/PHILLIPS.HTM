






<HTML>
     
     <HEAD>


          
          <TITLE>January 1996/The Backpropagation Neural Network</TITLE>
     </HEAD>
     
     <BODY BACKGROUND="" BGCOLOR="#FFFFFF" TEXT="#000000">
          
          <H2><A href="../tocjan.htm"><IMG src="../../toc.gif" ALT="Back to TOC" WIDTH="54" HEIGHT="54"></A>
          <FONT COLOR="#FF0000">Features</FONT></H2>
          
          <HR>
          
          <H2 ALIGN="center"><FONT COLOR="#800000">The Backpropagation Neural
          Network</FONT></H2>
          
          <H3 ALIGN="center"><FONT COLOR="#800000">by Dwayne Phillips</FONT></H3>
          
          <HR>
          <BLOCKQUOTE>
               
               <h4><FONT COLOR="#000080">Introduction</FONT></H4>
               
               <P>Neural networks are a capable
                    technology but they are still poorly understood by many
                    programmers. Neural networks learn how to recognize patterns
                    and solve problems that befuddle other types of computer
                    programs. Coded once, a good neural network program
                    (simulation) can be trained to solve a variety of different
                    problems. </P>
               
               <P> This article reviews some neural
                    network basics from a previous article I wrote for CUJ [<A href="#REF1">1</a>]

                    and demonstrates how to implement backpropagation &#151; a
                    versatile and widely used form of neural network.</P>
               
               <h4><FONT COLOR="#000080">Neural Network Basics</FONT></H4>
               
               <P>Neural
                    Networks existed in concept as far back as the 1960s. One of
                    the elements conceived at that time was the adaptive linear
                    combiner (<A href="fig1.htm">Figure 1</a>)
 &#151; the basic
                    building block of all neural networks. The adaptive linear
                    combiner multiplies the inputs (x) by the weights (w) and
                    yields the sum of these products. The C code for an adaptive
                    linear combiner is simple:</P>

<PRE>
ELEMENT x[], w[], result = 0.0
for (i = 0; i &lt; size; i++)
    result = result + x[i]*w[1];
</PRE>
               
               <P><BR>
                    <A href="fig2.htm">Figure 2</a>
shows the adaptive
                    linear element or Adaline &#151; the simplest neural network. It
                    consists of an adaptive linear combiner and a signum
                    function (output is -1 for negative input, +1 otherwise).
                    The Adaline feeds back an error to alter the weights. The
                    a-LMS learning law (described in my previous article) allows
                    you to train the Adaline to produce correct answers. My
                    previous article showed how to train the Adaline to solve
                    linearly separable problems such as shown in
                    <A href="fig3.htm">Figure 3</a>.
 </P>
               
               <P> <A href="fig4.htm">Figure 4</A>
                    shows the multiple adaptive linear element or Madaline. The
                    Madaline comprises several Adalines and a final decision
                    maker (the AND, OR, majority box). In [<A href="#REF1">1</a>]

                    I explained how the Madaline could distinguish non-linearly
                    separable patterns like that shown in <A href="fig5.htm">Figure
                         5</a>,
 and showed how the Madaline could recognize a
                    basic handwritten character. </P>
               
               <P> The Adaline and Madaline date back to
                    the early 1960s. Neural networks almost died in the 1970s,
                    but were reborn in the 1980s with the introduction of the
                    backpropagation network.</P>
               
               <h4><FONT COLOR="#000080">Backpropagation</FONT></H4>
               
               <P><A href="fig6.htm">Figure 6</A>
                    shows a backpropagation neural network. The table embedded
                    in the figure refers to source code variables &#151; you can
                    ignore it for now. The network has inputs (x) on the left,
                    outputs (y) on the right, several layers of connected nodes,
                    and a feedback loop (delta). The inputs feed forward through
                    the network of adaptive linear combiners. At each node the
                    sum of the products of inputs and weights goes through a
                    sigmoid function (<A href="fig7.htm">Figure 7</a>)
 that
                    compresses the result to between 0 and 1. This compression
                    provides a nonlinear characteristic. It also requires using
                    floating-point operations instead of the integers used in
                    the Adaline and Madaline. </P>
               
               <P> The backpropagation neural network
                    has several layers of nodes, unlike the Adaline, which had
                    only one node, and the Madaline which had one layer of
                    nodes. Multiple layers and more nodes can solve larger, more
                    complex problems. </P>
               
               <P> The backpropagation network also has
                    multiple outputs. The Adaline and Madaline had one output
                    with two states (-1 and +1). Multiple outputs allow multiple
                    output classes. The examples given later demonstrate the
                    power and flexibility of this feature. Multiple outputs also
                    mean multiple targets and deltas for training (explained
                    below). This requires an involved training algorithm.</P>
               
               <h4><FONT COLOR="#000080">Training a Network</FONT></H4>
               
               <P>Before it is used to solve a problem,
                    a neural network undergoes a sequence of steps known as
                    training. Training is an iterative process that adjusts the
                    weights at each node until the network is able to solve a
                    particular kind of problem (e.g. distinguish between several
                    handwritten characters). The training algorithm supplies the
                    network with a sequence of inputs and desired ouput values
                    (targets). The network is trained until it produces the
                    desired outputs from a set of inputs. During training,
                    deltas (targets - outputs) feed backwards through the
                    network to adjust the weights of the combiners. The
                    propagation of errors back through the network gives
                    backpropagation its name.</P>
               
               <h4><FONT COLOR="#000080">Propagating Errors
               Back Through the Network</FONT></H4>
               
               <P>Backpropagation's weight adjustment
                    (training) process is somewhat involved and difficult to
                    explain. Nevertheless, I'll take a crack at it. The math is
                    a bit confusing, but the final source code is simple. If you
                    are not a math fan, skip to the next section. </P>
               
               <P> The foundation of the process is the
                    sigmoid function and its derivative shown in equations (<A href="equat.gif">1</a>)

                    and (<A href="equat.gif">2</a>)
 and in
                    <A href="fig7.htm">Figure 7</a>.
 The sigmoid function
                    produces the final output of each neuron. "Almost
                    correct" answers fall near 0 or 1 while answers
                    contributing to error fall in the middle. Adjusting weights
                    is the job of the sigmoid derivative. The derivative is
                    greatest for middle values (those contributing the most
                    error) and small for larger values (almost correct).
                    Therefore, the derivative adjusts the "almost correct"
                    answers by a small amount and incorrect answers by a greater
                    amount. </P>
               
               <P> Equations (<A href="equat.gif">3</a>)

                    and (<A href="equat.gif">4</a>)
 show how to calculate
                    the error in the output (y) layer. The delta (<FONT FACE="Symbol">d</FONT>) is
                    the derivative of the output times the target minus the
                    output. Equation (<A href="equat.gif">4</a>)
 is actually
                    equation (<A href="equat.gif">3</a>)
 rewritten to
                    compute one element of a delta vector. Equation (<A href="equat.gif">5</a>)

                    shows how to change the weights in the output layer. </P>
               
               <P> Here, w<SUB>out</SUB> and <FONT FACE="Symbol">d</FONT>
                    refer to matrices and vectors respectively. 2&#181; is a
                    constant you can set at compile time (more on this later).
                    Changing the weights in the hidden and input layers follows
                    a similar process. The first step calculates the delta (h
                    delta) for each neuron output (h) in the network using
                    equation (<A href="equat.gif">6</a>)
. This is a
                    derivative just like that shown in equation (<A href="equat.gif">2</a>)
.
                    h and w refer to the current layer's neuron output vector
                    and weights matrix respectively. <FONT FACE="Symbol">d</FONT><SUB>prev </SUB>refers
                    to the vector of deltas calculated from the previous layer
                    (that is, the layer closer to the output layer). The second
                    step updates the weights throughout the network by using
                    equation (<A href="equat.gif">7</a>)
. This process
                    changes all the weights throughout the network during every
                    backward pass. The amount of change is proportional to the "error"
                    that each neuron contributes. The 2&#181; factor in
                    equations (<A href="equat.gif">5</a>)
 and (<A href="equat.gif">7</a>)

                    ensures the network does not correct too much and oscillate.</P>
               
               <h4><FONT COLOR="#000080">Using a Neural
               Network</FONT></H4>
               
               <P>Like other trainable neural networks,
                    using the backpropagation network requires three steps. The
                    first step is to enter data with known correct answers.
                    Second, train the weights in the network using the
                    backpropagation scheme described above. Third, use the
                    trained network on new data. Entering the data can be
                    tedious and error prone, but using ASCII files for input
                    eases this burden.</P>
               
               <h4><FONT COLOR="#000080">A Backpropagation
               Program</FONT></H4>
               
               <P>Now let us build a backpropagation
                    neural network program called backprop. Returning to
                    <A href="fig6.htm">Figure 6</a>,
 Inow direct your
                    attention to the embedded table I told to you ignore
                    earlier. This table gives the source code variables
                    corresponding to the components of the neural network.
                    </P>
               
               <P> The user provides the scalars m, n,
                    o, and p as input to backprop. Inputting these numbers gives
                    the user the flexibility to specify the size and shape of
                    the network at run time. backprop allocates all the arrays
                    dynamically. </P>
               
               <P> backprop is designed to operate in
                    one of three modes &#151; input, training, and "working"
                    mode. The program runs in the mode it was invoked with, then
                    shuts down. Between runs the program keeps most of its
                    arrays on disk. backprop uses six data files, to store the
                    inputs (x), the outputs (y), the targets, and the weights
                    for the network (win, whid, and wout). </P>
               
               <P> backprop also uses three optional
                    ASCII files. (While these are technically data files as
                    well, I call them ASCII files here to distinguish them from
                    the data files mentioned above.) The ASCII files make the
                    program easier to use by reducing repetitive typing and
                    allowing the user to alter inputs and target values by
                    editing rather than reentering. The ASCII parameters file 
                    specifies operational parameters such as input and output
                    file names, number of nodes per layer, and mode of
                    operation. An example is shown as follows: </P>
               
               <P></P>

<PRE>
mode training
m 2
n 4
o 3
p 5
data-sets 6
type sigmoid
in-file 2input.xxx
out-file 2output.xxx
target-file 2target.xxx
h-file 2h-file.xxx
win-file 2winfile.xxx
whid-file 2whidfil.xxx
wout-file 2woutfil.xxx
</PRE>
               
               <P><BR>
                     The ASCII input file allows the user to type the data
                    inputs (x array) in an ASCII file using an editor instead of
                    keying them into the program every time. The ASCII targets
                    file does the same for the target array.</P>
               
               <P>In the input mode, backprop reads the
                    parameters, input data, and targets from ASCII files and
                    saves the input and targets to data files. In the training
                    mode, backprop reads the parameters from an ASCII file and
                    the input and target data from data files. backprop trains
                    the network using the input and target data and then writes
                    the trained weights (win, whid, and wout) to data files. The
                    working mode is the simplest as backprop reads the
                    parameters from an ASCII file and the input data and weights
                    from data files. After processing the input data, backprop
                    writes the output to a data file.</P>
               
               <h4><FONT COLOR="#000080">A Look at the Source</FONT></H4>
               
               <P>What really goes on inside a neural
                    network program? For one thing, lots and lots of looping.
                    <A href="listing1.htm">Listing 1</a>
shows the code
                    segment for the training mode. This is the complicated mode
                    because training must continue until the program produces
                    the correct answer for every set of training data. First,
                    the program reads the sets of input data and the targets for
                    that data (read_from_file). After initializing the weights
                    in the network, the program moves into a set of while loops 
                    that continue until either the network produces correct
                    answers for every data set or the training exceeds a
                    TRAINING_LIMIT. </P>
               
               <P> The functions input_layer,
                    inner_layers, and output_layer calculate the outputs of the
                    input neurons, inner neurons, and output neurons
                    respectively, from the training input data. These same
                    functions are used in working mode. <A href="listing2.htm">Listing
                         2</a>
shows function input_layer. x is a
                    one-dimensional input array and win is a 2-D array of
                    weights. (Weights require a 2-D array because every neuron
                    has m weights.) The matrix_multiply function calculates
                    x*win and stores the resulting output (a vector) in tmp.
                    apply_function applies the sigmoid function to each element
                    of the vector tmp. (Making type anything other than "sigmoid"
                    causes the program to terminate.) Deep in its guts,
                    apply_function resolves to</P>

<PRE>
double a, b, c;
a = (double)(input_value)
b = exp (-1.0*a);
c = 1.0/(1.0 + b);
result = (ELEMENT)(C);
</PRE>
               
               <P></P>
               
               <P>The function copy_1d_to_2d copies the
                    vector tmp to one column of the neuron output matrix, h. (h
                    is 2-D because the network has n layers of p neurons each.)</P>
               
               <P>output_layer_error calculates the
                    delta between the output y and the target, using equation
                    <A href="equat.gif">4</a>.
 If the delta is small enough,
                    training on that data set ends. If not, neuron_deltas (<A href="listing3.htm">Listing
                         3</a>)
 calculates the errors in all the layers of the
                    network. </P>
               
               <P> change_output_weights,
                    change_hidden_weights, and change_input_weights modify the
                    weights using the equations shown earlier. When training
                    ends, the program writes the trained weights to data files.
                    </P>
               
               <P><A href="listing4.htm"> Listing 4
                    </A>shows the code segment for the working mode. In this
                    mode, the program reads the input data for the problem and
                    the trained weights for the network. The program processes
                    this data through the input, hidden, and output layers and
                    writes the answer to disk.</P>
               
               <h4><FONT COLOR="#000080">Solving Problems with
               Neural Nets</FONT></H4>
               
               <P>The following examples illustrate how
                    the backpropagation neural network can solve different
                    problems. Note that the source code remains the same while
                    the user trains the network for the different problems.
                    </P>
               
               <P> Be careful when training the
                    backpropagation neural network. backprop allows selection of
                    the layers in the network n and the neurons per layer p.
                    Specifying too many layers and neurons causes the weights to
                    memorize the inputs and outputs. Training stops after one
                    iteration, and the network cannot solve problems. Too few
                    layers and neurons cause the network to train forever 
                    because it doesn't have the capacity to adjust to all
                    training data sets. </P>
               
               <P> You can change the source code to
                    adjust the TWOMU and MIN_ERROR constants. TWOMU decides the
                    rate at which the weights change. If TWOMU is too large, the
                    weights change too much and training can oscillate. I found
                    TWOMU = 0.7 usually works. The MIN_ERROR constant determines
                    when the output is close enough to the target. I used 0.02
                    for most cases. </P>
               
               <P> <A href="fig8.htm">Figure 8</A>
                    shows a nonlinear problem where the backpropagation neural
                    network must classify two-dimensional inputs into one of
                    three output classes. I used four layers of neurons with
                    five neurons in each layer. I changed the MIN_ERROR constant
                    to 0.04, and the network needed 63 passes through all the
                    data sets to train itself. Notice how the multiple outputs
                    come into play here. The Madaline of [<A href="#REF1">1</a>]

                    could not tackle this problem because it had only one
                    output. </P>
               
               <P><A href="fig9.htm"> Figure 9 </A>shows
                    an example of using the backpropagation neural network to
                    recognize handwritten numbers. I wrote the numbers 1 through
                    8 in 5x7 arrays and shaded the squares containing any part
                    of the handwritten characters. The 35 squares are the inputs
                    to the neural network with shaded squares having the value 1
                    (0 for the white squares). There are eight output classes,
                    and a binary coding can represent these with only three
                    outputs. This shows another advantage of the multiple-output
                    capability of backpropagation neural networks. </P>
               
               <P> In the handwriting case, I used a
                    network with three layers having ten neurons per layer. This
                    worked well enough and trained itself in 108 passes through
                    the data shown. The network also trained itself when I
                    specified 20 neurons per layer (101 passes through the
                    data). After training, the backpropagation neural network
                    recognized similarly scrawled numbers.</P>
               
               <h4><FONT COLOR="#000080">Complete Source Code</FONT></H4>
               
               <P>The complete backprop source is
                    available on this month's code disk and via the online
                    sources listed on page 3.</p>
               
               <h4><FONT COLOR="#000080">Reference</FONT></H4>
               
               <P>[<A name="REF1">1</a>]
 Dwayne
                    Phillips. "The Foundation of Neural Networks: The
                    Adaline and Madaline," The C Users Journal, September
                    1992, pp. 69-92.</P>
               
               <P><I>Dwayne Phillips works as a
                    computer and electronics engineer with the U.S. Department
                    of Defense. He has a PhD in Electrical and Computer
                    Engineering from Louisiana State University. His interests
                    include computer vision, artificial intelligence, software
                    engineering, and programming languages.</I></P>


<h4><a href="../../../source/1996/jan96/phillips.zip">Get Article Source Code</a></h4>

</BLOCKQUOTE>
     </BODY>
</HTML>



<HTML>
<HEAD>

<TITLE>February 1993/Real-Number Approximation for Real Programmers</TITLE></HEAD>
<body bgcolor="#ffffff">
<H2><A HREF="../tocfeb.htm"><IMG SRC="../../toc.gif" ALT="{back to toc}" WIDTH="54" HEIGHT="54"></A><FONT COLOR="#FF0000">   Algorithms</FONT></H2>

<hr><h2 align="center"><font color="#800000">Real-Number Approximation for Real Programmers<A name="0046_0024"><A name="0046_0024"></font></h2><P>
<h3 align="center"><font color="#800000"><A name="0046_0000"><A name="0046_0000">Mark Gingrich</font></h3><hr><blockquote><P>
<P><i><A name="0046_0000"><A name="0046_0000">Mark currently works on real-time, embedded software in the medical device<I></I> <I></I>industry. Although trained in physics and computer science, he occasionally<I></I> <I></I>"moonlights" as an amateur astronomer. He can be reached at 355 Estabrook St., Apt. 403,<I></I> <I></I>San Leandro, CA 94577.</i></P><P>
<h4><FONT COLOR="#000080"><A name="0046_0025">Introduction<A name="0046_0025"></FONT></h4></P>
Real-world numerical calculations rarely, if ever, call for floating-point precision to the gazillionth digit. Indeed, do you really need to know your automobile's gas mileage to one-part-per-billion resolution?<P>
Of course, such practicalities influence the design of device software. And living at one computational extreme are those lean, mean microcontroller-embedded machines which often abstain from floating-point code. Yet it is frequently the case that an oddball transducer scaling factor or proportionality constant is required &#151; oddball in refusing to conform to our pristine integer-only universe. Hence the need to link in extra bytes from the floating-point math library into what is, all too often, a nearly full ROM space.<P>
This article describes a simple utility that computes integer-ratio approximations for floating-point constants. Code requiring only a few instances of floating point for scaling may instead use nearly equivalent integer ratios. The result is speed and size benefits by avoiding floating-point routines altogether.<P>
For example, instead of scaling a quantity by, say, 0.66666666, you could multiply by 2, then divide by 3. But this is a trivial case. A much more interesting question is: What integer ratios best approximate those perennially popular (and irrational) constants, such as the square root of 2, or <I>e</I>, or p?<P>
<h4><FONT COLOR="#000080"><A name="0046_0026">Approximating Pi by the Slice<A name="0046_0026"></FONT></h4></P>
Let's try <FONT FACE="Symbol">p</FONT>. The first few decimal digits are:<P>
<pre>3.14159265358979323846...</pre>
Chopping after the first two digits suggests the crude integer-ratio approximation 31/10. Reality differs by little more than one percent in this instance.<P>
But maybe that's not accurate enough. So tack on another digit. <FONT FACE="Symbol">p</FONT> then approximates to 314/100 (157/50 when reduced to lowest terms), just 0.05 percent from the truth. Continuing in this fashion for four more iterations yields the ratio:<P>
<pre>   3141593/1000000</pre>
with a mere 0.00001 percent error. Not bad for such a straightforward (I'll call it <I>radix-10</I>) method. Yet <FONT FACE="Symbol">p</FONT> is better approximated without so many digits.<P>
Although not immediately apparent, the ratio 355/113 is superior to<P>
<pre>   3141593/1000000</pre>
There are two compelling reasons why. First, 355/113 is nearer to <FONT FACE="Symbol">p</FONT>. Second, it has a smaller numerator (355 versus 3141593, the latter not even within 16-bit number range). Here is a crucial computational advantage. When a ratio is applied as a scaling factor, a smaller numerator permits larger multiplicands without overflow hassles.<P>
So 355/113 is better. But is it just a freakish occurrence? <A href="tab1.htm">Table 1</a>
implies otherwise. It shows a sequence of radix-10 rational approximations for <FONT FACE="Symbol">p</FONT> juxtaposed with a few "hand-picked" ratios (355/113 being one). Each of the latter provides better accuracy with smaller integers &#151; more accuracy per bit. Certainly it's not difficult to devise successively more accurate radix-10 ratios by inspection (31/10, 314/100, 3142/1000,...), but discovering these preferred "hand-picked" ratios is more subtle. There is a way to do so. It employs a mathematical device known as a <I>continued fraction</I>.<P>
<h4><FONT COLOR="#000080"><A name="0046_0027">Fractions, to be Continued<A name="0046_0027"></FONT></h4></P>
The continued-fraction form is a real number's alter ego. I'll intuitively illustrate the concept by creating a continued fraction for <FONT FACE="Symbol">p</FONT>. Take <FONT FACE="Symbol">p</FONT>'s decimal-digit sequence and break it into a sum of two components &#151; the integer part and the fractional part.<P>
<pre>3 + 0.1415926535897932...</pre>
Ignoring the fractional part for a moment, I could quit right here and claim that <FONT FACE="Symbol">p</FONT> is equal to 3 &#151; a first-cut estimate. Instead, I'll show a bit more initiative and improve the approximation. Rewrite the fractional part as follows:<P>
<IMG SRC="equat1.gif"><P>
Fixating on the denominator (7.06525133059310477...), I note again that I'm dealing with a real number. So break it into a sum of integer and fractional parts:<P>
<IMG SRC="equat2.gif"><P>
Like before, I may ignore the fractional component and stop at this point, leaving the result:<P>
<IMG SRC="equat3.gif"><P>
Or, yet again, I can improve the approximation. Rewrite the fractional denominator term:<P>
<IMG SRC="equat4.gif"><P>
The pattern to this algorithm now should be conspicuous. Break the bottom-most denominator into integer and fractional parts:<P>
<IMG SRC="equat5.gif"><P>
Ignoring the fractional component, I see that the approximation becomes:<P>
<IMG SRC="equat6.gif"><P>
For good measure, I'll do just one more iteration of this process:<P>
<IMG SRC="equat7.gif"><P>
And so on, and so on. These first few approximations should look familiar. They are the "hand-picked" ratios of <A href="tab1.htm">Table 1</a>.
 And I could continue generating still better ratios seemingly forever, or stop when I achieve the desired accuracy.<P>
This construct of nested fractions:<P>
<IMG SRC="equat8.gif"><P>
is called a <I>simple continued fraction</I>. It's "simple" because each numerator is unity. Given any nonnegative real number, <I>R</I>, the <I>a</I><I><SUB>i</SUB></I>s result by fiat of Algorithm A (<A href="fig1.htm">Figure 1</a>)
. Thus the <I>a</I><I><SUB>i</SUB></I>s needed to make <FONT FACE="Symbol">p</FONT> are:<P>
<pre>[3, 7, 15, 1, 292, 1, 1, 1, 2, 1, 3, 1, ...]</pre>
which is not as instantly recognizable as 3.14159..., but just as valid.<P>
Experimenting with this algorithm and a judicious assortment of real numbers reveals several notable continued-fraction characteristics:<P>
<UL><li>Rational numbers are expressible with a finite number of <I>a</I><I><SUB>i</SUB></I>s (for instance, 7/4 = 1.75 = [1, 1, 3]).</li>
<li>Irrational numbers require infinitely many <I>a</I><I><SUB>i</SUB></I>s.</li>
<li>The approximation of an irrational number improves with each successive <I>a</I><I><SUB>i</SUB></I>, always alternating between a-bit-too-large and a-bit-too-small values.</li>
<li>To handle negative real numbers, treat the value as if it were positive; then negate <I>a</I><I><SUB>0</SUB></I> and the top-most numerator.</li></UL>
Algorithm A is simple and intuitive &#151; but flawed in actual practice. The gotcha is the finite floating-point representation of real numbers. After a dozen or so iterations, erroneous <I>a</I><I><SUB>i</SUB></I>s are produced. The algorithm also can mess up after only a few iterations. The comparison test at the top of the loop often flubs because round-off prevents the fractional result from reaching zero exactly. A further annoyance arises from having to collapse the continued fraction to a simple fraction for use as a scaling factor.<P>
Algorithm B (<A href="fig2.htm">Figure 2</a>)
 sidesteps these pitfalls. It is a recurrence method using integers only. First you must decide how precisely &#151; how many digits &#151; you want to specify the real number of interest, then express it as a radix-10 ratio. For example, 3.1416 is 31416/10000. The algorithm starts out by producing a crude estimate, then grinds out additional ratios, <I>p[i]</I>/<I>q[i]</I>, each a simple fraction in lowest terms and more accurate than the previous one, until the initial radix-10 ratio is achieved. (Algorithm mavens will note a similarity to Euclid's algorithm. It's not a coincidence. See Knuth, 1981.)<P>
<h4><FONT COLOR="#000080"><A name="0046_0028">Real-World Usage<A name="0046_0028"></FONT></h4></P>
<A href="list1.htm">Listing 1</a>
details an implementation of Algorithm B in ANSI C. This short utility, called <I>fp2ratio</I>, accepts a floating-point number as a command-line argument and displays the ever-improving ratio approximations in succession. Output for a 9-digit representation of <FONT FACE="Symbol">p</FONT> appears in <A href="fig3.htm">Figure 3</a>.
<P>
But before applying one of these ratios as a scaling factor, a caveat. Keep in mind the round-off correction needed before division by the denominator (<I>denom</I>). Positive values are scaled thusly:<P>
<IMG SRC="equat9.gif"><P>
So much for the theory; let's try a practical application. Imagine a relatively noiseless sinusoidal signal digitized to 10-bit precision. The analog-to-digital converter scaling is 1 millivolt per least-significant bit. You wish to display, to three decimal-digit precision, the signal's root-mean-square (RMS) value in millivolts. Here's one strategy. Take the difference between the minimum and maximum signal excursions &#151; the peak-to-peak value &#151; then convert to RMS by scaling:<P>
<IMG SRC="equat10.gif"><P>
The peak-to-peak value is guaranteed never to exceed decimal 1,023. (It's a 10-bit result, remember.) So declare it an unsigned 16-bit word. As a guard against 16-bit overflow during scaling, the selected ratio's numerator must not exceed 64. <A href="fig4.htm">Figure 4</a>
shows <I>fp2ratio</I>'s output for the scaling factor<p>
<IMG SRC="equat11.gif"><P>
The best ratio honoring our overflow constraint is 35/99. Implementing the round-off correction, the scaling expression to appear in code is:<P>
<IMG SRC="equat12.gif"><P>
<h4><FONT COLOR="#000080"><A name="0046_0029">Conclusion<A name="0046_0029"></FONT></h4></P>
Another possible application of this approach is the "clean up" of numerical values due to loss of fidelity. Take, for example, the computation of a matrix inverse, where the matrix elements are known rationals. You crunch the numbers. You get your inverse &#151; along with unavoidable round-off and truncation effects. Yes, the answer is very close, but it's not an exact rational result. A bit of post-processing, a la the methods described, may help recover the true rational answer.<P>
Continued fractions, it turns out, are applied well beyond the ratio approximation of real numbers. Functions, too, may be approximated, but with polynomials replacing the integers in the numerators and denominators. This is an alternative to a power-series approximation (Press, 1986).<P>
But as handy as they are, continued fractions haven't achieved household-name status. The author Petr Beckmann has lamented that they are, "part of the 'lost mathematics,' the mathematics now considered too advanced for high school and too elementary for college." (Beckmann 1971)<P>
Real programmers are inveterate collectors of tricks and techniques. Consider adding continued fractions to your algorithm toolbox.<P>
<h4>References</FONT></h4></P>
Beckmann, Petr. 1971. <I>A History of Pi. </I>New York: Dorset Press.<P>
Knuth, Donald E. 1981. <I>The Art of Computer Programming. Volume 2: Seminumerical Algorithms</I>., 2nd ed. Reading, MA: Addison-Wesley.<P>
Olds, C.D. 1963. <I>Continued Fractions</I>. New York: Random House, New Mathematical Library.<P>
Press, William H., Flannery, Brian P., Teukolsky, Saul A., Vetterling, William T. 1986. <I>Numerical Recipes</I>. Cambridge, England: Cambridge University Press.<P>
Sinnott, Roger W. January, 1989. "Continued Fractions and the Sky". <I>Sky and Telescope</I>. 80-82.<P>
<h4><a href="tab2.htm">Table 2</a></h4>
<h4>Sidebar: <a href="sidebar1.htm">"Baseball, Mom, and Rational Pi"</a></h4>

<h4><a href="../../../source/1993/feb93/gingrich.zip">Get Article Source Code</a></h4>

</BLOCKQUOTE>
</BODY>
</HTML>








<HTML>
     
     <HEAD>


          
          <TITLE>November 1997/Coverage Testing with a C/C++ Profiler</TITLE>
     </HEAD>
     
     <BODY BACKGROUND="" BGCOLOR="#FFFFFF" TEXT="#000000">
          
          <H2><A href="../tocnov.htm"><IMG src="../../toc.gif" ALT="Back to TOC" WIDTH="54" HEIGHT="54"></A>
          <FONT COLOR="#FF0000">Features</FONT></H2>
          
          <HR>
          
          <H2 ALIGN="center"><FONT COLOR="#800000">Coverage Testing with a
          C/C++ Profiler</FONT></H2>
          
          <H3 ALIGN="center"><FONT COLOR="#800000">Paolo Argenton</FONT></H3>
          
          <BLOCKQUOTE>
               
               <P>There's lots of neat stuff packed in with gcc. It even helps
                    you do a pretty respectable job of test coverage analysis.</P></BLOCKQUOTE>
          <HR>
          <BLOCKQUOTE>
               
               <h4><FONT COLOR="#000080">The Need for Coverage
               Testing</FONT></H4>
               
               <p>I've always been intrigued by code
                    coverage testing, perhaps due to a form of imprinting: the
                    very first time I tried this technique &#151; on the most
                    frequently used program in my company &#151; I immediately found
                    a first-class bug. I quickly learned a lesson from this
                    experience and started applying what I had learned.</p>
               
               <p> Coverage testing belongs to the
                    so-called white-box, or structural testing methods. They are
                    so called because they use knowledge about the internals of
                    the program under scrutiny.</p>
               
               <p> The rationale behind coverage testing
                    is rather simple. You check the percentage of code being
                    exercised during tests, to know how much is actually tested,
                    and especially, to discover untested code. The code that
                    needs the most rigorous testing is not always obvious. For
                    instance, error-handling code has a higher percentage of
                    bugs than mainstream code, because during normal program 
                    usage it is not executed. Therefore, it is more likely to
                    contain undetected errors.</p>
               
               <p> The simplest form of coverage testing
                    is that of function-level coverage. It determines which
                    functions in your code have been called and which haven't.
                    While you may be confident from looking at your code that
                    every function is being processed, program flow is sometimes
                    counter-intuitive. Or, you may simply forget to test
                    something using non-automated tests.</p>
               
               <p> Consider the code fragment below,
                    which is similar to the program of my first test:</p>

<PRE>
...
     
/* argument processing:
   lot of options here */
while((ch = getopt(argc,argv,
  "u:t:r:m:SCB:ifn:p:RT:"   ))
   != EOF )
{
  switch( ch )
  {
     case 'u':   
     /* username */
...     
     case 'C':    
/* very rarely used option */
     enable_canc = TRUE;
     break;
...
   }
}
...
if ( enable_canc )
    do_something();
    /* very seldom executed */
...
</PRE>
               
               <p>Here it seems obvious from the context
                    that do_something was insufficiently tested. Even so, I can
                    attest that its bugs went unobserved for a long time.</p>
               
               <h4><FONT COLOR="#000080">Another Use for the
               Profiler</FONT></H4>
               
               <p>Now let's see what can be done with
                    available tools to improve the testing process. While I know
                    of no C/C++ compiler that comes integrated with coverage
                    testing tools, most C/C++ compilers probably come with a
                    profiler. Instead of using the profiler to find hot spots &#151;
                    that is, the functions that use most of the CPU time &#151; you
                    can use it the other way round, to find the functions never 
                    called.</p>
               
               <p> As an example I demonstrate the use
                    of GNU gprof, since GNU programs are widely available and
                    free, but other compilers have similar tools. Although I did
                    all the sample programs and tests on a PC running Linux,
                    there should be very few operating system dependencies.</p>
               
               <p> Suppose you want to test the simple
                    program given in<A href="list1.htm"> Listing 1</a>.
 First
                    you compile it with some special options:</p>

<PRE>
$ gcc -pg -o test01 test01.c
</PRE>
               
               <p>Then you run it:</p>

<PRE>
$ test01
</PRE>
               
               <p>And then you can analyze the profile
                    data. The following command creates a report file named
                    gmon.out:</p>

<PRE>
$ gprof -b -z test01 gmon.out
</PRE>
               
               <p>The output should be similar to that
                    given in <A href="tab1.htm">Table 1</a>.
 You can safely
                    ignore strange looking functions, such as
                    __do_global_ctors_aux, and all the data after the form feed
                    character. To weed out this extraneous data I wrote the awk
                    filter shown in <A href="list2.htm">Listing 2</a>.
 (You'll
                    have to adapt the string filtering if you use this technique
                    with different systems.)</p>
               
               <p> The command becomes:</p>

<PRE>
$ gprof -b -z test01 gmon.out | awk -f ignoref.awk
</PRE>
               
               <p>Now, looking at the results in
                    <A href="tab2.htm">Table 2</a>,
 you can quickly see that
                    f001 was never called.</p>
               
               <h4><FONT COLOR="#000080">Basic-Block Testing</FONT></H4>
               
               <p>At this point the goal is to achieve
                    100% function level coverage. In other words, you want to
                    make sure every function is called at least once. You can
                    accomplish this by adding other tests and using gprof's
                    cumulative option. But knowing which functions are called
                    guarantees nothing about what happens inside the functions.
                    You can easily imagine a function like the one below:</p>

<PRE>               
int buggy()
{  if ( low_probability )
  {
    /* buggy code here */
  }
  else
    /* correct code here */
}
</PRE>
               
               <p>To adequately test functions such as
                    this you must go beyond 100% function level coverage. You
                    must check that every possible path within every function is
                    being executed.</p>
               
               <p> There are several opinions on the
                    best way to proceed. For instance, you could test that every
                    Boolean condition in the if statements is tested at least
                    once for true and false values. This technique is called
                    branch, or decision testing.</p>
               
               <p> One idea I find pretty natural and
                    easy to develop is to check the execution of every block of
                    code. This enables me to test every possible execution path.
                    I say this idea is "easy to develop" because, from this
                    level of detail on, it is very difficult to find or adapt
                    existing tools. Luckily I discovered, almost by chance, a
                    feature in the gcc compiler named basic-block profiling.</p>
               
               <p> Let's say, for the sake of
                    simplicity, that a basic block is a sequence of statements
                    without internal branching constructs. gcc's -a option
                    allows you to profile your program in a manner similar to
                    the -pg option, but at basic-block level instead of function
                    level. When you run a program compiled this way you will
                    find, after execution, a bb.out file. gcc always writes to 
                    this file by appending, a feature that comes in handy for
                    executing multiple tests.</p>
               
               <p> gcc creates this file via its runtime
                    library. If you want to dig in the code, the function name
                    is __bb_exit_func in file libgcc2.c A sample bb.out is shown
                    in <A href="tab3.htm">Table 3</a>.
 The more interesting
                    fields are the line number, which marks where the basic
                    block begins; a count of how many times the block was
                    executed; the file name; and the function name.</p>
               
               <p> Given all of the above, here's a
                    typical way to use basic-block programming manually:</p>
               
               <p> Compile the program. (The -g option
                    is important; it enables output of file name and line number
                    information.)</p>

<PRE>
$ gcc -g -a -o test01 test01.c
</PRE>
               
               <p>Delete bb.out, if it exists:</p>

<PRE>
$ rm bb.out
</PRE>
               
               <p>Run the program:</p>

<PRE>
$ test01
</PRE>
               
               <p>Now you can see the results by looking
                    in the bb.out file. You can find out by inspection which
                    blocks were never executed. But of course, since the file
                    could reflect the results of multiple tests, this method is
                    pretty impractical. So I developed a little awk program that
                    prints out only the blocks that were never executed
                    throughout the whole set of tests.</p>
               
               <p>The awk program in
                    <A href="list3.htm">Listing 3</a>
is straightforward; the
                    only thing to note is an interesting feature of arrays in
                    awk: you can use a string as the index of the array. The
                    index I use is a string made by concatenating the file name
                    and line number. For every line of data read in from bb.out
                    the awk program increments a counter. After the program
                    reaches the end of the file it  prints the elements of the
                    array whose values are still zero, that is, the blocks that
                    were never executed in the whole set of tests. The program
                    also prints some statistics.</p>
               
               <p> Now, from the beginning: you want to
                    test the program test01. Compile it with:</p>

<PRE>
$ gcc -g -a -o test01 test01
</PRE>
               
               <p>Then run it:</p>

<PRE>
$ rm bb.out
$ test01
</PRE>
               
               <p>Now you condition the test results
                    with:</p>

<PRE>
$ gawk -f pblock.awk bb.out
</PRE>
               
               <p>Sample output appears in
                    <A href="tab4.htm">Table 4</A></p>
               
               <p>The last number appearing in<A href="tab4.htm">
                         Table 4</a>
is the percentage of code coverage. If you
                    are unsatisfied with this number you must look at the former
                    lines, which are the line numbers of blocks never executed,
                    and find a way to exercise them. In this trivial example you
                    should add a test like the following:</p>

<PRE>
$ test01 other-argument-supplied
</PRE>
               
               <p>The sample output is:</p>

<PRE>
00008 blocks out of 00008 executed; 100% coverage
</PRE>
               
               <p>Now if you look at the results you
                    will be happy to see 100% code coverage.</p>
               
               <h4><FONT COLOR="#000080">Conclusion</FONT></H4>
               
               <p>Of course this home-built tool can not
                    compete with commercial packages; however, it has some nice
                    properties:</p>
               <UL><LI> It is open and easily
                         expandable. (For instance I was thinking about adding
                         an interface to Emacs, to highlight the uncovered
                         lines.)</FONT></LI>
                    <LI> It is free and simple. Thus you
                         can use it as a gentle introduction to the coverage
                         testing.</FONT></LI>
                    <LI> It is language independent. I
                         tested the gcc's -a option with C, Ada, and Fortran. o</FONT></LI>
               </UL>
               
               <h4><FONT COLOR="#000080">References</FONT></H4>
               
               <p>Roger S. Pressman. Software
                    Engineering: A Practitioner's Approach (McGraw-Hill, 1996)
                    ISBN 0-07-052182-4. </p>
               <p><i>Paolo Argenton is a freelance consultant and programmer. He has been
                    programming in C and C++ since 1983. His interests include software quality
                    assurance, reliability, and safety. Paolo can be reached at
                    paolo.argenton@iol.it.</i></p>
     
<h4><a href="../../../source/1997/nov97/argent.zip">Get Article Source Code</a></h4>

     </BLOCKQUOTE>
     </BODY>
</HTML>

<HTML>   
     <HEAD>
<TITLE>February 2000/An Introduction to Interpolation</TITLE></HEAD>
<BODY BACKGROUND="" BGCOLOR="#FFFFFF" TEXT="#000000">
<H2><A HREF="../tocfeb.htm"><IMG SRC="../../toc.gif" ALT="{back to toc}" WIDTH="54" HEIGHT="54"></A><FONT COLOR="#FF0000">   Embedded Systems</FONT></H2>

<HR>

<H2 ALIGN="center"><FONT COLOR="#800000">An Introduction to Interpolation</FONT></H2>
<H3 ALIGN="center"><FONT COLOR="#800000">Kyle Loudon</FONT></H3>

<BLOCKQUOTE>
<p>There's more to mathematical interpolation than just drawing lines between dots.</p>
</BLOCKQUOTE>

<HR>
<BLOCKQUOTE>
<p>Interpolation is a mathematician's version of "connect the dots." More formally, it is a way of approximating the value of a function at various points using a limited number of values known at others. The ability to do this is important in many applications. For example, imagine a program that requires the use of wind velocities predicted for various locations and altitudes around the world. Here it would be prohibitively costly (and wasteful) to store values for every location and altitude required. Instead, you just need a good idea of the winds at a limited number of points; you can then <I>interpolate</I> between them. Another use of interpolation is to replace more complicated functions with simpler ones so that operations such as differentiation and integration become easier. Human beings are perhaps the best interpolators of all. If you flash a sequence of static images before your eyes fast enough (say, of a horse running), your brain will fill in the gaps.</p>
<p>This article presents five methods for interpolating functions using a computer. Each method is based on the construction of polynomials. Polynomials are an important part of the interpolation process because they have a simple structure, which makes them easy to work with in a variety of contexts. Specifically, this article presents interpolation using Lagrange polynomials, interpolation using Newton polynomials, piecewise-linear interpolation, piecewise-cubic Hermite interpolation, and piecewise-cubic Bessel interpolation. The article concludes with a brief discussion of techniques for estimating interpolation error.</p>

<H4><FONT COLOR="#000080">Interpolation Using Lagrange Polynomials</FONT></H4>

<p>The goal of polynomial interpolation is as follows: given a set of n + 1 points x<SUB>0</SUB>,...,x<SUB>n</SUB> on the interval I = [a, b] over which we know the value of a function f(x), construct a polynomial that satisfies the equation below.</p>

<IMG SRC="eq1.gif" width=20%></p>

<p>The polynomial that satisfies this is said to interpolate the function f(x). For a set of n + 1 points, this polynomial is of degree &lt;= n. The importance of p(x) is that once you have found it, you can use it to approximate f(x) at values of x not in x<SUB>0</SUB>,...,x<SUB>n</SUB>, provided these values are on the interval I. The standard way to represent a polynomial in mathematical discussions is in the power form, shown below. This is generally the most familiar form. Provided a<SUB>n</SUB> is nonzero, this polynomial is said to be of degree n.</p>

<IMG SRC="eq2.gif"></p>

<p>Although the power form of a polynomial is common, other polynomial forms are more useful in some contexts. For example, the Lagrange form, shown below, is particularly useful in the context of interpolation.</p>

<IMG SRC="eq3.gif"></p>

where</p>

<IMG SRC="eq4.gif"></p>

<p>For a set of n + 1 points x<SUB>0</SUB>,...,x<SUB>n</SUB> along a function f(x), you would construct the Lagrange form of a polynomial with n = 2 as follows:</p>

<IMG SRC="eq5.gif" width=50%></p>

<p>Since each function l<SUB>k</SUB>(x) is a product of n linear factors, each l<SUB>k</SUB>(x) is a polynomial of exact degree n; consequently, the Lagrange form as a whole describes a polynomial of degree n.</p>
<p>Considering the Lagrange form further, notice that l<SUB>k</SUB>(x) becomes 0 at x<SUB>i</SUB> for all i<IMG SRC="embed1.gif" height="14" width="14" hspace="5">k, and 1 when i = k. Therefore, you can make the statement below.</p>

<IMG SRC="eq6.gif"></p>

<p>In other words, the coefficients a<SUB>0</SUB>,...,a<SUB>n</SUB> in the Lagrange form are the values of the polynomial p(x) at the points x<SUB>0</SUB>,...,x<SUB>n</SUB>. Replacing a<SUB>0</SUB>,...,a<SUB>n</SUB> with the values of f(x) at x<SUB>0</SUB>,...,x<SUB>n</SUB> yields the following formula, which produces a polynomial of degree &lt;= n that interpolates f(x) at x<SUB>0</SUB>,...,x<SUB>n</SUB>.</p>

<IMG SRC="eq7.gif"></p>

This is the <I>Lagrange formula</I> for the interpolating polynomial. <a href="list1.htm">Listing 1</a> shows how to use this formula in a program.</p>

<H4><FONT COLOR="#000080">Example 1</FONT></H4>

<p>This example uses Lagrange polynomials to interpolate a function f(x) describing the lift produced by the wing of a large commercial aircraft as a function of airspeed at a fixed altitude and wing configuration. Suppose you know the values of f(x) at x<SUB>0</SUB> = 100 ft/sec, x<SUB>1</SUB>= 500 ft/sec, and x<SUB>2</SUB> = 900 ft/sec, which are as follows:</p>

<pre>
<I>f</I>(100) = 7882.1 lbs
<I>f</I>(500) = 197052.5 lbs
<I>f</I>(900) = 638450.1 lbs
</pre>

<p>To compute the lift produced at x = 600 ft/sec, for example, you perform the calculations shown below. Compute the lift for other values of x in a similar manner.</p>

<IMG SRC="eq8.gif"></p>
<IMG SRC="eq9.gif" width=70%></p>
<IMG SRC="eq10.gif" width=70%></p>
<IMG SRC="eq11.gif"></p>

<p><a href="fig1.htm">Figure 1</a> shows the results of approximating f(x) at x = 200, x = 400, x = 600, and x = 800 ft/sec using the three points known for f(x) presented previously.</p>
<p>In this example, since there are three points at which f(x) is known, the interpolating polynomial is of degree &lt;= 2. It turns out that the function for lift is, in fact, a second-degree polynomial when written in terms of airspeed. Therefore, <a href="fig1.htm">Figure 1</a> is a good representation of f(x). The discussion on error later presents a more quantitative explanation of why this is the case.</p>
<p>Interpolation using Lagrange polynomials is a nice method in such cases when you know exactly how many points you need to use to get a good impression of f(x). However, in practice, you often don't know this. In these situations, it is common to compute several interpolating polynomials p<SUB>k</SUB>(x) of increasing degree &lt;= k (i.e., p<SUB>0</SUB>(x), p<SUB>1</SUB>(x), p<SUB>2</SUB>(x), etc.) until |p<SUB>k</SUB>(x) - p<SUB>k-1</SUB>(x)|(k &gt;= 1) is less than some tolerance. When interpolating using Lagrange polynomials, you must compute each successive p<SUB>i</SUB>(x) from scratch, which ends up being more work than necessary. Interpolation using Newton polynomials offers a more efficient approach.</p>

<H4><FONT COLOR="#000080">Interpolation Using Newton Polynomials</FONT></H4>

<p>In the previous section, you saw how the Lagrange form is one alternative to the power form for representing a polynomial. Another polynomial form relevant to interpolation is the Newton form, shown below. Provided an is nonzero, this polynomial is said to be of degree n.</p>

<IMG SRC="eq12.gif"></p>

<p>The variables x<SUB>0</SUB>,...,x<SUB>n-1</SUB> are <I>centers,</I> and in the case of polynomial interpolation, are the first n of the n + 1 interpolation points. To construct the interpolating polynomial in the Newton form, replace each a<SUB>k</SUB> with f[x<SUB>0</SUB>,...,x<SUB>k</SUB>], k = 0,...,n.</p>

<IMG SRC="eq13.gif"></p>

<p>This is the <I>Newton formula</I> for the interpolating polynomial, which is often written more succinctly in the form that follows. Each f[x<SUB>0</SUB>,...,x<SUB>k</SUB>] is the kth <I>divided difference</I> of f(x) at points x<SUB>0</SUB>,...,x<SUB>k</SUB>.</p>

<IMG SRC="eq14.gif"></p>

<p>To compute the value of each f[x<SUB>0</SUB>,...,x<SUB>k</SUB>], the coefficients of the interpolating polynomial, use the procedure described next. Let f[x<SUB>0</SUB>] = f(x<SUB>0</SUB>) and f[x<SUB>0</SUB>, x<SUB>1</SUB>] = (f(x<SUB>1</SUB>) - f(x<SUB>0</SUB>)) / (x<SUB>1</SUB> - x<SUB>0</SUB>), which you can verify algebraically by manipulating p<SUB>1</SUB>(x) derived from the Lagrange formula as outlined below.</p>

<IMG SRC="eq15.gif"></p>
<IMG SRC="eq16.gif"></p>
<IMG SRC="eq17.gif"></p>
<IMG SRC="eq18.gif"></p>
<IMG SRC="eq19.gif"></p>
<IMG SRC="eq20.gif"></p>
<IMG SRC="eq21.gif" width=50%></p>

<p>Compute higher-order divided differences using the formula below, which assumes n + 1 interpolation points. Notice how each divided difference depends on computing others before it.</p>

<IMG SRC="eq22.gif"></p>

<p>The best way to perform these calculations in an orderly fashion is with a <I>divided-difference</I> table. A divided-difference table consists of several rows. In the top row, place the values x<SUB>0</SUB>,...,x<SUB>n</SUB>. In the second row, place the values f[x<SUB>0</SUB>] = f(x<SUB>0</SUB>),...,f[x<SUB>n</SUB>] = f(x<SUB>n</SUB>). Then, to compute each divided difference in the remainder of the table, draw a diagonal from each divided difference back to f[x<SUB>i</SUB>] and f[x<SUB>i+k</SUB>]. To get x<SUB>i</SUB> and x<SUB>i+k</SUB> in the denominator, proceed straight up from f[x<SUB>i</SUB>] and f[x<SUB>i+k</SUB>]. The two divided differences in the numerator are the two immediately above the one being computed. Once you have populated the entire table, the coefficients for the interpolating polynomial are the divided differences at the far left of each row, in order, beginning with the second row.</p>
<p><a href="fig2.htm">Figure 2</a> illustrates a divided-difference table generated for four points. As mentioned earlier, one of the nice things about interpolation using Newton polynomials is that it lets you proceed more efficiently than the Lagrange form when computing polynomials p<SUB>k</SUB>(x) of increasing degree &lt;= k until |(p<SUB>k</SUB>(x) - p<SUB>k-1</SUB>(x)|(k &gt;= 1) is less than some tolerance. To understand this, let q<SUB>k</SUB>(x) be the sum of the first k + 1 terms of p<SUB>n</SUB>(x) for some k between 0 and n. In this case, each of the remaining terms has the factor (x - x<SUB>0</SUB>)...(x - x<SUB>k</SUB>); thus, you can write p<SUB>n</SUB>(x) in the form that follows, where r(x) is a polynomial of no interest for now.</p>

<IMG SRC="eq23.gif"></p>

<p>Since (x - x<SUB>0</SUB>)...(x - x<SUB>k</SUB>)r(x) becomes 0 when x is any point in x<SUB>0</SUB>,...,x<SUB>k</SUB>, q<SUB>k</SUB>(x) already interpolates f(x) at x<SUB>0</SUB>,...,x<SUB>k</SUB>. Since q<SUB>k</SUB>(x) is a polynomial of degree &lt;= k, it follows that q<SUB>k</SUB>(x) = p<SUB>k</SUB>(x); therefore, q<SUB>k</SUB>(x) is the polynomial of degree &lt;= k that interpolates f(x) at x<SUB>0</SUB>,...,x<SUB>k</SUB>. This is important because it means that you can construct each successive p<SUB>k</SUB>(x) incrementally from its predecessor, p<SUB>k-1</SUB>(x). To compute pk(x), add pk-1(x) to the next term in the Newton form, as shown below.</p>

<IMG SRC="eq24.gif"></p>

<p><a href="list2.htm">Listing 2</a> shows how to perform this process in a program. Note that when compared with interpolation using Lagrange polynomials, interpolation using Newton polynomials usually requires computing a polynomial one degree larger than what you might expect; consequently, one additional interpolation point is required as well. The polynomial of one degree larger is p<SUB>k</SUB>(x), which must be used to determine when |p<SUB>k</SUB>(x) - p<SUB>k-1</SUB>(x)| is less than the tolerance.</p>

<H4><FONT COLOR="#000080">Example 2</FONT></H4>

<p>This example uses Newton polynomials to approximate values of f(x) = sin x given nine interpolation points: x<SUB>i</SUB> = i<FONT FACE="Symbol">p</FONT>/4, i = 0,...,8, as follows:</p>

<pre>
<I>f</I>(0) = 0.0	<I>f</I>(<FONT FACE="Symbol">p</FONT>/4) = 0.7071068
<I>f</I>(<FONT FACE="Symbol">p</FONT>/2) = 1.0	<I>f</I>(3<FONT FACE="Symbol">p</FONT>/4) = 0.7071068
<I>f</I>(<FONT FACE="Symbol">p</FONT>) = 0.0	<I>f</I>(5<FONT FACE="Symbol">p</FONT>/4) = -0.7071068
<I>f</I>(3<FONT FACE="Symbol">p</FONT>/2) = -1.0	<I>f</I>(7<FONT FACE="Symbol">p</FONT>/4) = -0.7071068
<I>f</I>(2<FONT FACE="Symbol">p</FONT>) = 0.0
</pre>

<p>To compute the value of f(x) at x = 3<FONT FACE="Symbol">p</FONT>/8 = 1.17810 so that |p<SUB>k</SUB>(x) - p<SUB>k-1</SUB>)(x)| &lt; 0.001 (k &gt;= 1), for example, you end up computing p<SUB>0</SUB>(x),...,p<SUB>6</SUB>(x). This process is illustrated below.</p>

<IMG SRC="eqinsert.gif"></p>
<IMG SRC="eq25.gif"></p>
<IMG SRC="eq26.gif"></p>

<p>...</p>
<IMG SRC="eq27.gif"></p>
<IMG SRC="eq28.gif"></p>
<IMG SRC="eq29.gif"></p>
<IMG SRC="eq30.gif"></p>
<IMG SRC="eq31.gif"></p>
<IMG SRC="eq32.gif"></p>

<p>Interpolation using Newton polynomials is nice in cases when you know that f(x) is simple enough that it can be approximated to within the desired tolerance using a relatively small number of interpolation points (say &lt;= 10). However, since interpolation using Newton polynomials (as well as Lagrange polynomials) involves constructing a single polynomial to interpolate f(x) at each of the interpolation points across the entire interval of interest, increasing the number of points complicates the overall interpolation process. When interpolating more complicated functions, such as functions involving frequent changes in concavity, more points are required. In these cases, one of the following piecewise approaches is preferable.</p>

<H4><FONT COLOR="#000080">Piecewise-Linear Interpolation</FONT></H4>

<p>To interpolate a function in a piecewise manner, you break it logically into a series of pieces and interpolate each piece individually. In piecewise-linear interpolation, you interpolate each piece using a first-degree polynomial. This means that two points are required to interpolate each piece, and the curve between each pair of points is a straight line (hence the term "linear"). Formally, given a series of n + 1 values for f(x<SUB>i</SUB>), i = 0,...,n, x<SUB>0</SUB> &lt; ... &lt; x<SUB>n</SUB>, you approximate f(x) at some point x by determining the interval [x<SUB>k</SUB>, x<SUB>k+1</SUB>] on which x resides and performing the calculation below using x<SUB>k</SUB> and x<SUB>k+1</SUB> as the interpolation points.</p>

<IMG SRC="eq33.gif"></p>

<p>The advantage of piecewise-linear interpolation is that although f(x) may be complicated, the polynomials that interpolate the pieces of f(x) are not. Furthermore, once you understand interpolation using Newton polynomials, it's easy to see that piecewise-linear interpolation is just a simplified case, applied several times instead of just once.</p>
<p><a href="list3.htm">Listing 3</a> shows how to perform piecewise-linear interpolation in a program. As an illustration, <a href="fig3.htm">Figure 3a</a> depicts the first second of ground motion associated with a minor earthquake recorded by the Berkeley Digital Seismic Network. The tremor occurred in Woodside, CA (near San Francisco) as a result of one of the largest eucalyptus trees in the United States toppling to the ground. <a href="fig3.htm">Figure 3b</a> shows the linear pieces that result from interpolating the curve in <a href="fig3.htm">Figure 3a</a> using a linear-form interpolating polynomial with interpolation points equally spaced at x<SUB>i</SUB> = 0.05i seconds, i = 0,...,20. One thing you may notice in <a href="fig3.htm">Figure 3b</a> is that as the distance between interpolation points decreases, the lines that interpolate the pieces of f(x) decrease as well; consequently, the error associated with each piece becomes smaller. The discussion on error later presents a more quantitative explanation of why this is the case. Another way to reduce the error is to use higher-order polynomials to interpolate the pieces. Cubic polynomials are particularly popular.</p>

<H4><FONT COLOR="#000080">Piecewise-Cubic Hermite Interpolation</FONT></H4>

<p>Piecewise-cubic Hermite interpolation is similar to piecewise-linear interpolation. It too involves breaking a function logically into a series of pieces that are then interpolated individually. However, in piecewise-cubic Hermite interpolation, as in all piecewise-cubic methods, you interpolate each piece using a third-degree polynomial. Four points are thus required to interpolate each piece; consequently, the resulting curve fits the piece closer than a straight line would in most cases.</p>
<p>Formally, to approximate f(x) at some point x, given a series of n + 1 values for f(x<SUB>i</SUB>), i = 0,...,n, x<SUB>0</SUB> &lt; ... &lt; x<SUB>n</SUB>, you determine the interval [x<SUB>k</SUB>, x<SUB>k+1</SUB>] on which x resides and evaluate the third-degree interpolating polynomial. Considering this, if x<SUB>k</SUB> and x<SUB>k+1</SUB> are the only two points for which you know values for a piece of f(x), it's worth asking where the other two of the four requisite points come from. Different piecewise-cubic interpolation methods answer this question in different ways. Piecewise-cubic Hermite interpolation answers the question by selecting the points x<SUB>k</SUB>, x<SUB>k</SUB>, x<SUB>k+1</SUB>, and x<SUB>k+1</SUB>. Selecting these points ensures two things: first, that p(x) agrees with f(x) at x = x<SUB>k</SUB> and x = x<SUB>k+1</SUB> (as with any interpolating polynomial); and second, that p'(x), the derivative of p(x), also agrees with f'(x), the derivative of f(x), at x = x<SUB>k</SUB> and x = x<SUB>k+1</SUB>. The Newton form of the interpolating polynomial generated from these points is shown below.</p>

<IMG SRC="eq34.gif"></p>

<p>In this polynomial, each of the four coefficients, call them a<SUB>0</SUB>, a<SUB>1</SUB>, a<SUB>2</SUB>, and a<SUB>3</SUB>, is a divided difference expressed in terms of x<SUB>k</SUB> and x<SUB>k+1</SUB>. To determine the value of each coefficient, use the formulas that follow. To see where these formulas come from, construct a divided-difference table using the points x<SUB>0</SUB> = x<SUB>k</SUB>, x<SUB>1</SUB> = x<SUB>k</SUB>, x<SUB>2</SUB> = x<SUB>k+1</SUB>, and x<SUB>3</SUB> = x<SUB>k+1</SUB>. In the table, wherever you see (f(x<SUB>k+1</SUB>) - f(x<SUB>k+1</SUB>))/(x<SUB>k+1</SUB> - x<SUB>k+1</SUB>), replace it with f'(x<SUB>k+1</SUB>); wherever you see (f(x<SUB>k</SUB>) - f(x<SUB>k</SUB>))/(x<SUB>k</SUB> - x<SUB>k</SUB>), replace it with f'(x<SUB>k</SUB>). <a href="list4.htm">Listing 4</a> shows how to perform piecewise-cubic Hermite interpolation in a program.</p>

<IMG SRC="eq35.gif" width=15%></p>
<IMG SRC="eq36.gif" width=30%></p>
<IMG SRC="eq37.gif"></p>
<IMG SRC="eq38.gif"></p>

<p>Notice that piecewise-cubic Hermite interpolation requires the value of f'(x) at each interpolation point in addition to the value of f(x). In practice, this requirement for f'(x) is sometimes problematic. You may be able to get values for f'(x) when interpolating a function whose values have been stored in a function table; however, there are many cases when obtaining these values will be either difficult or not possible at all. When this is true, you can approximate f'(x). This is called piecewise-cubic Bessel interpolation.</p>

<H4><FONT COLOR="#000080">Piecewise-Cubic Bessel Interpolation</FONT></H4>

<p>Piecewise-cubic Bessel interpolation is similar to piecewise-cubic Hermite interpolation, except that it substitutes an approximation for f'(x) in the computation of coefficients for the interpolating polynomial. In piecewise-cubic Bessel interpolation, you carry out the same computations as those presented for a<SUB>0</SUB>, a<SUB>1</SUB>, a<SUB>2</SUB>, and a<SUB>3</SUB> above, except you use the formula below for each f'(x<SUB>k</SUB>). This formula requires the use of two additional points, one to the left of x<SUB>0</SUB> and one to the right of x<SUB>n</SUB>, to give some number for derivatives when interpolating the leftmost and rightmost pieces. <a href="list4.htm">Listing 4</a> performs piecewise-cubic Bessel interpolation when you use approximations for f'(x).</p>

<IMG SRC="eq39.gif"></p>

<H4><FONT COLOR="#000080">Estimating Interpolation Error</FONT></H4>

<p>This section describes the error associated with the various interpolation methods presented in this article. Fundamentally, the interpolation error e<SUB>n</SUB>(x) associated with any interpolating polynomial p<SUB>n</SUB>(x) of degree &lt;= n interpolating a function f(x) is defined by the equation below.</p>

<IMG SRC="eqinser2.gif" width=40%></p>

<p>Of course, normally you won't know f(x), so you must look for a way to estimate the value of e<SUB>n</SUB>(x) in practice. Assuming X to be some point different from x<SUB>0</SUB>,...,x<SUB>n</SUB>, let p<SUB>n+1</SUB>(x) be the polynomial that interpolates f(x) at x<SUB>0</SUB>,...,x<SUB>n</SUB> and X as well. In other words, p<SUB>n+1</SUB>(X) = f(X). Recall that you can construct the interpolating polynomial p<SUB>n+1</SUB>(x) from the interpolating polynomial of one degree smaller, p<SUB>n</SUB>(x), using the Newton form. Therefore, since p<SUB>n+1</SUB>(x) interpolates X, the error in p<SUB>n</SUB>(x) is given by the next term added to p<SUB>n</SUB>(x), which produces p<SUB>n+1</SUB>(x).</p>

<IMG SRC="eq40.gif"></p>

<p>This still doesn't help you much, though, because to compute f[x<SUB>0</SUB>,...,x<SUB>n</SUB>, X], the need for f(x) remains. However, it turns out that f[x<SUB>0</SUB>,...,x<SUB>n</SUB>, X] is closely related to the (n + 1)st derivative of f(x). Therefore, when you know a bound for f<SUP>(n + 1)</SUP>(x), call it M, over the entire interval you are interpolating, you can use it to obtain a bound (albeit a broad one) for the error. Considering this, the formula below is used to estimate interpolation error.</p>

<IMG SRC="eq41.gif"></p>

<p>The variable <FONT FACE="Symbol">x</FONT> in the formula is a rarely-known value that depends on the point X at which you desire the error estimation. It appears in the formula because interpolation error varies depending on where you look along f(x). This makes sense when you think of how an interpolating polynomial often yields approximations for f(x) that are better at some points than others (which is why I mention Chebyshev points below). Since you almost never know <FONT FACE="Symbol">x</FONT>, the key is to replace f<SUP>(n+1)</SUP>(<FONT FACE="Symbol">x</FONT>) with the bound M mentioned a moment ago.</p>
<p>One interesting thing to notice in the error formula is that when you use n + 1 points to interpolate a function (thus producing an interpolating polynomial of degree n), f<SUP>(n+1)</SUP>(<FONT FACE="Symbol">x</FONT>) becomes 0; consequently, the interpolation error becomes 0 as well, regardless of the value of <FONT FACE="Symbol">x</FONT>. This explains quantitatively why when interpolating the second-degree function for lift in the first example, for instance, interpolation with three points produced a good representation of the second-degree function.</p>
<p>From the basic error formula, you can derive formulas for piecewise-linear interpolation and piecewise-cubic Hermite interpolation as well, which are listed in order below (assuming interpolation over the interval I = [a,b] and n + 1 interpolation points). There are two things to notice in these formulas: first, you can reduce the interpolation error as small as necessary by making the distance between interpolation points smaller for all k; and second, you can reduce the error by using interpolating polynomials of a greater degree for each of the pieces (as in the case of trying piecewise-cubic interpolation as opposed to piecewise-linear interpolation).</p>

<IMG SRC="eq42.gif"></p>
<IMG SRC="eq43.gif"></p>

<p>Another aspect of interpolation error is how uniformly well a polynomial interpolates a function across an entire interval of interest. This depends on the placement of the interpolation points. For this, I encourage you to research the significance of Chebyshev points. The reference <a href="#1">[1]</a> provides an excellent description.</p>

<H4><FONT COLOR="#000080">Summary</FONT></H4>

<p>This article has presented several types of interpolation methods along with brief explanations on when to apply them. To review, interpolation using Lagrange polynomials is a nice way to understand the existence of the interpolating polynomial, and is useful when you know the number of points required to give a good impression of a function. Interpolation using Newton polynomials is a good approach when you need to compute polynomials of increasingly larger degree to find one that approximates a function within a desired tolerance. Piecewise approaches (piecewise-linear interpolation, piecewise-cubic Hermite interpolation, and piecewise-cubic Bessel interpolation) are good for interpolating more complicated functions (functions that require the use of more than ten interpolation points). All piecewise approaches work by logically breaking functions into pieces that are interpolated individually. Piecewise approaches vary in the degree of the polynomials used to interpolate the pieces as well as in which points are selected as interpolation points.</p>
<p>You can use the interpolation methods presented in this article to solve interpolation problems found in many applications. For a more extensive treatment, there is a great deal of research and academic literature on the subject to which you can refer. <a href="#1">[1]</a>, <a href="#2">[2]</a>, and <a href="#3">[3]</a> are some good examples.</p>

<H4><FONT COLOR="#000080">References</FONT></H4>

<p><a name="1"></a>[1]  Samuel D. Conte and Carl de Boor. <I>Elementary Numerical Analysis: An Algorithmic Approach</I> (McGraw-Hill, 1980). This book provides a particularly good mathematical presentation of interpolation methods.</p>
<p><a name="2"></a>[2]  William H. Press, Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery. <I>Numerical Recipes in C: The Art of Scientific Computing</I> (Cambridge University Press, 1993). This is a popular reference regarded by many engineers, scientists, and software developers as particularly friendly. It also has the benefit of being available in its entirety online at <B>http://www.ulib.org/webRoot/Books/Numerical_Recipes</B>.</p>
<p><a name="3"></a>[3]  Michael C. Kohn. <I>Practical Numerical Methods: Algorithms and Programs</I> (Macmillan Publishing Co., 1987). This book provides nice illustrations for visualizing how some of the methods presented in this article work.</p>

<p><b><i>Kyle Loudon</B> currently works for Pixo, Inc. in Cupertino, CA, a company developing web technologies, application software, and a graphics-rich user interface for mass-market wireless phones. Before Pixo, Kyle worked as the technical leader of graphical user interface development at Jeppesen Dataplan and as a system programmer for IBM. He has a B.S. in computer science from Purdue University and has done advanced study at Stanford University. He is the author of <I>Mastering Algorithms with C</I>, published by O'Reilly &amp; Associates.</i></p>

<h4><a href="../../../source/2000/feb00/loudon.zip">Get Article Source Code</a></h4>


</blockquote></body></html>

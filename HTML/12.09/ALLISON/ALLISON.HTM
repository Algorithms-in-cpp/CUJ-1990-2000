

<HTML>
<HEAD>

<TITLE>September 1994/Code Capsule</TITLE></HEAD>
<body bgcolor="#ffffff">
<H2><A HREF="../tocsep.htm"><IMG SRC="../../toc.gif" ALT="{back to toc}" WIDTH="54" HEIGHT="54"></A><FONT COLOR="#FF0000">   Columns</FONT></H2>

<hr><h2 align="center"><font color="#800000">Code Capsule<A name="017B_00CD"><A name="017B_00CD"></font></h2><P>
<h3 align="center"><A name="017B_0000"><A name="017B_0000">Conversion and Casts</h3><P>
<h3 align="center"><font color="#800000">Chuck Allison</font></h3><hr><blockquote><P>
<P><i><A name="017B_0000"><A name="017B_0000">Chuck Allison is a regular columnist with CUJ and a software architect for the Family History Department of the Church of Jesus Christ of Later Day Saints Church Headquarters in Salt Lake City. He has a B.S. and M.S. in mathematics, has been programming since 1975, and has been teaching and developing in C since 1984. His current interest is object-oriented technology and education. He is a member of X3J16, the ANSI C++ Standards Committee. Chuck can be reached on the Internet at 72640.1507@compuserve.com.</i></P><P>
Since C was invented mainly for systems programming, it has features that are "close to the machine." These features include increment and decrement operators (which usually map to a single machine instruction), bitwise operations, pointers and addressing operators, and a rich set of low-level data types. What other language has eight flavors of integers? It is essential for a C/C++ programmer to know how objects of different types interact. A compiler implicitly converts objects from one type to another when different data types are intermixed, such as in arithmetic expressions, or when an object is assigned or passed as an argument to a different type of object. In some cases the conversion merely reinterprets rather than alters the underlying bit pattern (although the conversion may also3 widen or narrow the object). In this article I will explain these implicit standard conversions, user-defined conversions, and the explicit conversion capability available through the cast mechanism, including C++ new-style casts.<P>
<h4><FONT COLOR="#000080"><A name="017B_00CE">Integral Promotion<A name="017B_00CE"></FONT></h4></P>
In an environment where short, int, and long are all distinct sizes, the eight integral types obey the following sequence of inequalities with respect to the maximum value each can represent:<P>
<pre>signed char      &lt;unsigned char  &lt;signed short
&lt;unsigned short  &lt;signed int     &lt;unsigned int
&lt;signed long     &lt;unsigned long</pre>
In most environments, however, int is equivalent to either a short or a long. In any case, integral expressions operate only on objects of type int and long, or their unsigned varieties. So when an object of an integral type narrower than int occurs in an expression, the compiler <I>promotes</I> it to an int (or unsigned int, if needed) for the computation. Consider the following code fragment:<P>
<pre>char cl: 100, c2=200, c3= c1 + c2;
printf("%d\n",c3);</pre>
In an environment where a char is an 8-bit byte, this fragment will print the value <I>44</I> (see <A href="list1.htm">Listing 1</a>)
. The interesting feature of this program is what happens to <I>c2.</I> Why does <I>c2</I> print as -<I>56</I> in <A href="list1.htm">Listing 1</a>?
Except for the <I>char</I> *format specification, the compiler does not type-check arguments to <I>printf</I>, therefore <I>c2</I> is promoted to int before <I>printf</I> sees it. A compiler is free to implement a plain char as either a signed or unsigned char. As you can see, the compiler I use in this example, Borland C++, uses signed char. A standard-conforming compiler promotes a signed char to an int using <I>sign extension</I>, meaning that it populates the extra high-order bits with the original char's sign bit. A char holding the value 200 (<I>0xC8</I>) has a sign bit (its most significant bit) of <I>1</I>, so it promotes to an int containing <I>0xFFC8</I> (see <A href="list2.htm">Listing 2</a>)
. The program then calculates the sum<P>
<pre>     0064
+    FFC8
  -------
= (1)002C</pre>
which truncates to <I>0x2C</I> or <I>44</I>.<P>
<A href="list3.htm">Listing 3</a>
shows what happens when you use an unsigned char instead. The sum <I>300</I> overflows the maximum value a byte can hold. The result equals the overflow amount, which can be expressed as a modulus operation:<P>
<pre>44 == 300 % 256</pre>
where <I>256</I> == <I>UCHAR_HAX</I> + 1. (<I>UCHAR_MAX</I> is defined in &lt;<I>limits.h</I>&gt;).<P>
<A href="list4.htm">Listing 4</a>
shows that unsigned chars promote by filling the high-order bits of the new object with zeroes. In this case the program computes the sum<P>
<pre>    0064
+   00C8
  ------
=   012C</pre>
which truncates to <I>0x2C</I>, which again is <I>44</I>.<P>
The difference in promoting signed vs. unsigned quantities can be significant. For example, the "dump" program in <A href="list5.htm">Listing 5</a>
prints each byte of its input file as two hexadecimal digits, sixteen per row, followed by the corresponding ASCII representation (see the output in <A href="list6.htm">Listing 6</a>)
. If I hadn't declared the array <I>buf</I> as unsigned, any byte values greater than or equal to 128 would display with an extra, prepended <I>FF</I>, misaligning the output (recompile and see for yourself).<P>
In C++, objects of enumeration type promote to either int, unsigned int, long, or unsigned long, whichever is the smallest type that can represent all values of the enumeration. Although <I>wchar_t</I>, the "wide character" type, is a distinct, overloadable type in C++, it otherwise behaves as its underlying implemention type, which is one of the integer types. When assigning a value of the new C++ type <I>bool</I> to an integer, <I>false</I> becomes <I>0</I> and <I>true</I> becomes <I>1</I>.<P>
<h4><FONT COLOR="#000080"><A name="017B_00CF">Exercise<A name="017B_00CF"></FONT></h4></P>
Examine the output of the program in <A href="list7.htm">Listing 7</a>.
 The two sides of the assignment<P>
<pre>y = x+x;</pre>
print differently. Why.? (See answer at the end of this article.)<P>
<h4><FONT COLOR="#000080"><A name="017B_00D0">Demotions<A name="017B_00D0"></FONT></h4></P>
The result of converting an integer to a narrower unsigned type is the remainder of division by 2n, where n is the unsigned type's length in bits. This explains why, in <A href="list3.htm">Listing 3</a>,
 converting <I>300</I> to unsigned char resulted in <I>44</I>. Such a conversion is called a <I>demotion</I>, or equivalently, a <I>narrowing conversion</I>. If the narrower type is signed, however, the result is implementation-defined if the smaller type cannot represent the larger value. As <A href="list8.htm">Listing 8</a>
shows, my compiler just truncates high-order bits, if necessary, and interprets the demoted value according to two's-complement arithmetic. For example, the bit pattern for <I>60000U</I> is<P>
<pre>    1110 1010 0110 0000</pre>
But if this value is to become a <I>signed</I> integer, it must represent a negative number, because its sign bit is set. To determine the magnitude of this negative integer, the two's-complement rules say to flip the bits and add 1:<P>
<pre>   0001 0101 1001 1111
+                    1
   -------------------
=  0001 0101 1010 0000</pre>
which is 5536, so <I>(int)60000U == -5536</I>.<P>
The bit pattern for <I>70000L</I> is:<P>
<pre>    0000 0000 0000 0001 0001 0001 0111 0000</pre>
The conversion to short (which is the same as int in my 16-bit environment) simply truncates the top sixteen bits. Since its sign bit is not set, this short now represents the positive number <I>4464</I>.<P>
Converting a floating-point number to an integer discards the fractional part, truncating toward zero. When a floating-point value is too large to fit in an integer, the result is undefined.<P>
As you would expect, when an integer is converted to <I>bool</I> in C++, a non-zero value becomes <I>true</I>, and zero <I>false</I>.<P>
<h4><FONT COLOR="#000080"><A name="017B_00D1">Arithmetic Conversions<A name="017B_00D1"></FONT></h4></P>
Working with floating-point numbers has been likened to moving piles of sand &#151; every time you move one you lose a little. A finite floating point number system can represent only a small portion of the set of real numbers and large integers. When these numbers are involved in calculations, the system substitutes the closest representable number. <A href="list9.htm">Listing 9</a>
illustrates this process. The roundoff error inherent in finite-precision arithmetic caused the product <I>100 * 23.4</I> to land closer to <I>2339</I> than <I>2340</I>.<P>
Standard C defines three levels of floating-point precision: float (single precision), double (double precision), and long double (extended precision). The set of representable float values is a subset of representable doubles, which in turn is a subset of representable long double numbers. C interprets unadorned constants, such as 100.0, as type double. To force a constant to be of another floating type, you can use a suitable suffix, as <A href="tab1.htm">Table 1</a>
illustrates.<P>
Demoting a floating-point number to another floating-point type of smaller precision, (as in double to float), produces three possible outcomes, depending on the value of the number being demoted:<P>
1)     The number being demoted (the source number) is outside the target type's range. In this case, the result is defined.<P>
2)     The source number is within the target type's range but is not representable by the target type. The result is the nearest higher or lower value, depending on the rounding algorithm used (which is implementation -defined).<P>
3)     The source number is exactly representable in the target precision, in which case there is no error.<P>
The program in <A href="list10.htm">Listing 10</a>
shows that <I>ULONG_MAX</I>, the largest unsigned long integer (4,294,967,295 in my 16-bit environment, is not representable in my compiler's set of floats, but <I>ULONG_MAX1</I>, is because it's a power of two, and the floating-point number system is binary-based. Both double and long double have sufficient precision to represent <I>ULONG_MAX</I>, however.<P>
When two numbers of different types appear as operands in an arithmetic operation, the compiler balances the expression by either converting one type to the other, or, in the case of small integers, converting both to a common type. If either operand is of floating-point type, then the compiler converts the narrower type object to the larger floating-point type. If both arguments are integers, they undergo integral promotion so that the operands temporarily become either int or long (or their unsigned versions, as appropriate) &#151; then the object of narrower type is converted to the wider type for the operation. In other words, C and C++ promote the types used in a dual operand numeric operation upward within one of the following prioritized lists, depending on the relationship between long and int:<P>
<pre>If sizeof(long) &gt; sizeof(int):
-----------------------------
long double
double
float
unsigned long
unsigned int
int

If sizeof(long) == sizeof(int):
------------------------------
long double
double
float
unsigned long == unsigned int
long == int</pre>
<h4><FONT COLOR="#000080"><A name="017B_00D2">Function Prototypes<A name="017B_00D2"></FONT></h4></P>
Function prototypes do more than just type-check function arguments at compile time. When necessary, they also automatically convert arguments to the type of the corresponding parameter. For example, a common error unchecked by old-style function definitions (i.e., without prototypes) is to pass an integer argument to a double parameter:<P>
<pre>   f(1);
   /* Big trouble! f expects a double */
   ...

void f(x)
double x;
{
   ...</pre>
As <A href="list11.htm">Listing 11</a>
illustrates, providing a fully-prototyped declaration of such a function before you use it forces an implicit conversion from <I>int</I> to <I>double</I>. <A href="list11.htm">Listing 11</a>
also shows that a narrowing conversion, in this case from <I>double</I> to <I>int</I>, can be dangerous (because the integer representation of 1.0e6 is undefined in a 16bit environment).<P>
You are responsible for <I>unchecked arguments</I>. For example, in the following prototype for <I>printf</I>, the ellipsis specificationindicates that any number of arguments of any type may follow the first parameter:<P>
<pre>printf(const char *,...);</pre>
Since the compiler has no way of knowing what these should be, it can't catch the following error:<P>
<pre>#include &lt;stdio.h&gt;

main()
{

   int x = 1;
   printf("%ld\n",x);
   /*Mismatch!*/
   return 0;
}

/* Output:
65537
*/</pre>
The compiler can perform only <I>default promotions</I> on unchecked arguments, which consist of integral promotion and converting type <I>float to double</I>.<P>
<h4><FONT COLOR="#000080"><A name="017B_00D3">Explicit Conversions<A name="017B_00D3"></FONT></h4></P>
The conversions discussed so far are all implicit conversions &#151; they happen without any intervention on your part. You can explicitly request a conversion at any time with a cast operator. For example, in the following assignment, the fractional part of x has no effect:<P>
<pre>int i;
double x;
/*...*/
i=i+x;</pre>
However, the code runs through the following laborious sequence:<P>
1.     Convert <I>i</I> to a double.<P>
2.     Add <I>(double)i</I> to <I>x</I> using double arithmetic.<P>
3.     Truncate the result to an integer and assign to <I>i</I>.<P>
If you're counting nanoseconds, you can avoid the double arithmetic by casting <I>x</I> to an <I>int</I>:<P>
<pre>i = i + (int)x;</pre>
Casts can come in handy when dealing with pointers. If you need to inspect the bytes of an integer, for example, you can do this:<P>
<pre>int i;
char *cp = (char *) &amp;i;
char hi_byte = *cp++; /* if big-endian*/
char lo_byte = *cp;
/* etc. */</pre>
The cast is necessary to convince the compiler that you know what you're doing, since it normally doesn't allow mixing pointers to different types. C does not require casts when assigning to and from pointers to <I>void</I>, as is illustrated by the function in <A href="list12.htm">Listing 12</a>,
 which inspects the bytes of any object (sample output is in <A href="list13.htm">Listing 13</a>)
. However, in C++, it is an error to assign from a void pointer without a cast. To compile <A href="list12.htm">Listing 12</a>
as a C++ program, change the declaration of <I>p</I> to:<P>
<pre>const unsigned char *p = (const unsigned char *) ptr;</pre>
C++ also allows <I>function-style casts</I>. For example, you can rewrite the statement<P>
<pre>i = i + (int)x;</pre>
as<P>
<pre>i = i + int(x);</pre>
Besides being easier on the eye, this notation is compatible with the use of constructors for creating temporaries and initializing objects, as in:<P>
<pre>#include "foo.h"      //defines class Foo
Foo f: Foo(1) + Foo(2);</pre>
In this case, class <I>Foo</I> must have a constructor that takes a single integer argument. See the section on user-defined conversions below for more detail.<P>
One drawback to function-style casts is that they allow only single-token type names. For example, the following statement is illegal:<P>
<pre>const unsigned char *p = const unsigned char *(p);</pre>
The work-around for this problem is to use a typedef:<P>
<pre>typedef unsigned char *const_ucharp;
const unsigned char *p = const_ucharp(p);</pre>
<h4><FONT COLOR="#000080"><A name="017B_00D4">Const Correctness<A name="017B_00D4"></FONT></h4></P>
The const qualifier is a critical component of the C type system, and even more so for <I>C++</I>. Whenever you create a read-only pointer or read-only reference function parameter you should declare it const. Consider the following implementation of <I>memcpy</I>:<P>
<pre>void *memcpy(void *to. const void *from, size_t n)
{
   char *to_p = to;
   const char *from_p = from;
   while (n--)
      *top++: *from_p++;
   return to;
}</pre>
The source buffer pointer (<I>from</I>) is declared as a <I>pointer to const</I>, meaning that the function has no intention of altering what it points at. This declaration not only guards against inadvertent assignment within the function, but allows you to pass a pointer to const as an argument. If the const qualifier were missing in the definition of <I>memcpy</I>, then you could not pass <I>t</I> as an argument in the following:<P>
<pre>char *s = ... ;
const char *t = ... ;
memcpy(s,t,10);</pre>
The compiler needs a guarantee that <I>memcpy</I> will not try to modify what t points at. With <I>const</I> in the prototype, you can use pointers to both const and non-const.<P>
All of the above applies to references as well as pointers. A common idiom for passing objects by value in C++ is to pass a const reference:<P>
<pre>void g(const Foo&amp; f);</pre>
This guarantees that <I>g</I> will not modify <I>f</I>.<P>
You can also declare that a pointer itself cannot change by placing <I>const</I> after the asterisk:<P>
<pre>char * const p;
*p = 'a'; // OK, only the
        //pointer is const
++p; // Error, can't
    //modify pointer</pre>
To disallow modification of both the pointer and the contents referenced, use <I>const</I> in both places:<P>
<pre>const char * const p;
char c;
c = *p; // OK - can read contents
*p = 'a';        // Error
++p;             // Error</pre>
A <I>const member function</I> in a C++ class promises not to modify the object to which it applies. For example, a date class might have separate functions to inspect and to alter the number of the month:<P>
<pre>class Date
{
   int month_;
   // rest of implementation omitted
public:
   int month() const; // return month
   void month(int);  // change month
   // etc.
};</pre>
The observer function is declared const, because it just returns the current value. Therefore, both of the following function invocations are valid:<P>
<pre>const Date d1;
Date d2;
d1.month();
d2.month ();</pre>
But you can't change <I>d1</I> 's month, as in<P>
<pre>d1.month(10);</pre>
because you can't call a non-const member function for a const object. The compiler detects the error by inspecting the type of the object's hidden <I>this</I> pointer. When the object is non-const, the type of <I>this</I> is<P>
<pre>Date * const;</pre>
meaning "<I>this</I> is a const pointer to <I>Date</I>." So you can't alter <I>this</I> (that would be weird, anyway), but you can alter what it points to, therefore you can change its private data within a non-const member function. On the other hand, if the underlying object is const, then <I>this</I> has the following declaration:<P>
<pre>const Date * const this;</pre>
which disallows modifying any members. Const member functions expect such a <I>this</I> pointer, so if you invoke one with a non-const object, there is a mismatch and the compiler complains.<P>
Nevertheless, sometimes you may want to alter a data member within a const member function. For example, a function may not need to alter anything that the user is aware of, but may want to update some private state variable (this situation is common in classes that cache values). You still want to enable the user to invoke the function for const members, since s/he doesn't need to know about your optimization secrets. This use of the const concept is sometimes called <I>semantic const-ness</I> (as opposed to <I>bitwise const-ness</I>). Consider the following class definition, for example:<P>
<pre>class B
{
public:
   void f() const;
private:
   int state;
};</pre>
To allow <I>B::f</I> to alter <I>state</I>, and still be called for const objects, you "cast away const" in the implementation of <I>f</I>:<P>
<pre>void B::f() const
{
   ((B*)this)-&gt;state = ...;
   ...
}</pre>
Recall that the type of <I>this</I> in <I>f</I> is const <I>B</I> * <I>const</I>. The expression <I>(B*)this</I> suspends the const-ness temporarily, allowing you to make the assignment.<P>
<h4><FONT COLOR="#000080"><A name="017B_00D5">User-Defined Conversions<A name="017B_00D5"></FONT></h4></P>
A class constructor that takes a single argument defines an implicit conversion from the type of that argument to the type of the class. For example, the rational number class (<A href="list14.htm">Listing 14</a>, <A href="list15.htm">Listing 15</a>, 
<A href="list16.htm">Listing 16</a>, and <A href="list17.htm">Listing 17</a>)
 has the following constructor:<P>
<pre>Rational(int n = 0, int d = 1);</pre>
which allows zero, one, or two arguments when initializing a rational number. The declaration above ensures that whenever an integer appears in an expression with a <I>Rational</I> object, the integer is implicitly converted to a <I>Rational</I> with a denominator of <I>1</I>. This implicit conversion allows statements such as the following to be meaningful:<P>
<pre>Rational y(4);
cout &lt;&lt; 2 / y &lt;&lt; endl;</pre>
When the compiler sees the expression<P>
<pre>2/y</pre>
it looks for a global function with signature <I>operator/(int, Rational)</I>. Failing that, it notices the existence of the function <I>operator/(const Rational&amp;,const Rational&amp;)</I>, in addition to the built-in <I>operator/(int, int)</I>. The compiler therefore looks for a conversion of either <I>int</I> to <I>Rational</I>, or <I>Rational</I> to <I>int</I>. If both conversions existed (which they don't here), the compiler would complain, since it wouldn't know which one to pick. Because class <I>Rational</I> allows a constructor with a single integer argument, the compiler uses that to convert 2 to <I>Rational(2)</I>, and then invokes <I>operator/(Rational (2),y)</I>.<P>
It is significant that <I>operator/(const Rational&amp;, const Rational&amp;)</I> is a global function. If I had defined <I>operator/</I>as a member function, instead, as in<P>
<pre>Rational Rational::operator/(const Rational&amp;)</pre>
then the compiler would be able to evaluate the expression <I>y/2</I>, but not <I>2/y</I>, because member operator functions require the left operand to be an object of their class. You could of course provide functions to service all possible combinations of operands:<P>
<pre>// These handle r/r, r/i, and i/r, resp.
Rational Rational::operator/(const Rational&amp;)
Rational Rational:: operator/(int);
friend Rational operator/(int, const Rational&amp;);</pre>
This strategy requires no conversions at all from <I>int</I> to <I>Rational</I>, but can be quite tedious in classes with a large number of operators. Defining global operator functions in conjunction with appropriate constructors allows symmetric, mixed-mode binary operations with minimum fuss.<P>
Although you don't want to in this case (because of the ambiguity mentioned above), how would you define an implicit conversion from <I>Rational </I>to<I> int?</I> There is no <I>int</I> class definition available to which you can add single-argument constructors whenever you need a conversion from a new type to <I>int</I>. As an alternative, you need some way within a source class definition to provide a conversion from the source class type to other types, even to built-in ones. You can do this conversion with a <I>conversion operator function</I>. To implicitly convert objects of a source class to target type <I>T</I>, just define the following function as a member of the source class:<P>
<pre>operator T() const;</pre>
For an implicit <I>Rational</I>-to-<I>int</I> conversion, you would add the following to class <I>Rational</I>:<P>
<pre>// Return integer part:
operator int() const {return hum/den;}</pre>
In general, you don't want implicit conversions going both ways, since the compiler will not know which function to choose for a dual-operand operation. If you feel you must have a conversion from <I>Rational</I> to <I>int</I>, make it an explicit conversion with a member function, such as<P>
<pre>int to_int() const {return num/den;}</pre>
and call it when you need it, as in<P>
<pre>int i : r.to_int();</pre>
String classes sometimes include a <I>char*</I> conversion operator; this operator allows string objects to be used as arguments to the ANSI-C string functions that require a <I>char*</I> argument, for example<P>
<pre>string s;
strcpy(s, "hello");</pre>
<A href="list18.htm">Listing 18</a>
shows that you still must be careful about using such conversions with functions with unchecked arguments. The expression<P>
<pre>(char *) s</pre>
invokes <I>string::operator char*</I> and returns a pointer to data, as expected. But since the second and subsequent arguments to <I>printf</I> are unchecked, no implicit conversion takes place in the second invocation of <I>printf</I>.<P>
<h4><FONT COLOR="#000080"><A name="017B_00D6">Beefing-Up <B><I>operator[]</I><A name="017B_00D6"></B></FONT></h4></P>
Most string class implementations include a member function with the following signature:<P>
<pre>char&amp; operator[](size_t);</pre>
<I>operator[]</I><I>'</I>s implementation usually goes something like this:<P>
<pre>char&amp; string::operator[](size_t pos)
{
   return data[pos];
}</pre>
where <I>data</I> is the underlying array of characters. This member function provides the typical subscripting action that no programmer can live without. A common use:<P>
<pre>string s;
char c: s[0];</pre>
Because <I>string::operator[]</I> returns a reference, it can be used as an lvalue, as in the assignment<P>
<pre>s[0] = 'a';</pre>
What if different actions are required, depending on whether the subscript is on the left-hand vs. the right-hand side of the assignment? Such is the case with the <I>bitstring</I> class in the standard C++ library (see <A href="list19.htm">Listing 19</a>, <A href="list20.htm">Listing 20</a>, and <A href="list21.htm">Listing 21</a>;
 also "Bit Handling in C++, Part 1," <I>CUJ</I>, December 1993). An expression such as:<P>
<pre>bitstring b;
int n = b[0];</pre>
stores either a one or a zero in <I>n</I>, and is equivalent to<P>
<pre>int n = b.test(0);</pre>
The operation<P>
<pre>b[0] = n;</pre>
either sets or resets the zeroth-bit of <I>b</I>, and is equivalent to<P>
<pre>if (n)
   b.set(n);
else
   b.reset(0);</pre>
Since the two operations are quite different, we need some way of distinguishing when the subscripting occurs on the left vs. the right side of an assignment. The solution is to introduce a new class, which I call <I>bitref</I>, with only two public member functions: an assignment operator and an implicit integer conversion. Class <I>bitref</I>, which I have nested within the bitstring class, privately maintains a reference to the bitstring it will index, and the index position itself. The constructor is private so only a bitstring object can create a temporary bitref object (bitstring is a friend to bitref.)<P>
The function <I>bitstring::operator[]</I> just returns a temporary bitref object &#151; nothing more. Therefore, the assignment<P>
<pre>int n = b[i];</pre>
which is equivalent to<P>
<pre>int n = b.operator[](i);</pre>
becomes<P>
<pre>int n = bitref(b,i);</pre>
The compiler naturally looks for a conversion from <I>bitref</I> to <I>int</I>, which it finds in <I>bitstring::bitref::operator int()</I>, which returns either a zero or a one for the assignment to <I>n</I>.<P>
For the lvalue case, the statement<P>
<pre>b[i] = n;</pre>
becomes<P>
<pre>bitref(b,i) = n;</pre>
which in turn invokes<P>
<pre>bitref(b,i).operator=(n);</pre>
which either sets or resets the <I>i</I>th bit of <I>b</I>, depending on the value of <I>n</I>.<P>
<h4><FONT COLOR="#000080"><A name="017B_00D7">New-Style Casts<A name="017B_00D7"></FONT></h4></P>
A cast is your way of telling the compiler to allow you to do something potentially dangerous, because you think you know what you're doing. Too often, though, you don't know what you're doing (no offense!), and you spend days tracking down an insidious pointer conversion error or similar bug. It's interesting that programmers use a single cast notation for so many different purposes:<P>
<UL><li>to reinterpret the bit pattern of an object</li>
<li>to widen or narrow a value</li>
<li>to traverse a class hierarchy</li>
<li>to cast-away <I>const</I> or <I>volatile</I></li>
<li>to do some implementation-dependent magic</li></UL>
The new-style casts in C++ attempt to minimize the chances for error by categorizing the different types of operations for which you typically use casts. If you cast incorrectly, C++ tells you, either at compile time or run time, depending on the situation.<P>
C++ defines four new cast mechanisms: dynamic_cast, static_cast, reinterpret_cast, and const_cast.<P>
A dynamic_cast provides safe <I>downcasts</I>. You can always do an <I>upcast</I>, i.e,, you can always cast a pointer to derived class to a pointer to a base class, as in:<P>
<pre>class B {...};
class D =public B {...} ;
D d;
B* bp = (B*) &amp;d;</pre>
This is safe because a D <I>is a </I>B. But casting from a <I>B*</I> to a <I>D*</I> only makes sense if you know that the referenced object is in fact a <I>D</I>. This type of pointer conversion is called a downcast because it travels "down" the class hierarchy (because most people draw base classes at the top of a class diagram). To determine whether or not such a cast is safe requires run-time type information (RTTI). A C++ compiler keeps run-time information for objects of all <I>polymorphic</I> types (i.e., types that have at least one virtual function). The <I>dynamic_cast</I> operator returns a null pointer if the downcast is unsafe, otherwise it returns the original pointer cast to the new type, as in:<P>
<pre>D* dp = dynamic_cast&lt;B*&gt; bp;
if (dp)
   // okay to use dp for stuff
   // specific to a D object.</pre>
Note that all of the new-style casts use template-like bracket notation for the target type.<P>
The other three new-style cast operators are compile-time mechanisms. You use <I>static_cast</I> when you really <I>do</I> know that a <I>B*</I> points to a <I>D*</I>, so run-time checking isn't necessary. You also use it for invoking standard and user-defined conversions explicitly, which probably makes <I>static_cast</I> the most widely used category of casts for code that is being migrated from C.<P>
<I>reinterpret_cast</I> is the "don't ask, don't tell" cast &#151; it is for doing everything except navigating a class hierarchy (which it does not allow). You can use it to convert any type to any other, for reasons best kept to yourself. It is just about as unsafe as traditional cast notation, except that you're not likely to use it much due to the presence of the other three newstyle casts, and because it sticks out like a sore thumb:<P>
<pre>int j;
int *ip = &amp;j
char *cp = reinterpret_cast&lt;char *&gt;(ip);
// trust me!</pre>
<I>const_cast</I>, as you may have surmised, makes abundantly clear your intentions to cast-away <I>const:</I><P>
<pre>void B::f() const
{
// Modify data member of a const object:
   (const_cast&lt;B*&gt;(this))-&gt;state =
...;
   ...
}</pre>
The target type can drop a <I>const</I> or <I>volatile</I> qualifier that is part of the argument type's definition. For example, in the above statement <I>this</I> is of type <I>const B*</I>, but the target type is mere <I>B*</I>. However, in all other respects the target and argument types must match.<P>
<h4><FONT COLOR="#000080"><A name="017B_00D8">Summary<A name="017B_00D8"></FONT></h4></P>
Standard C defines a host of implicit conversions to allow convenient intermixing of its varied types in expressions. I have tried to show how these conversions work and when they can get you into trouble. With single-argument constructors and conversion operators, C++ allows user-defined types to behave as much as possible like built-in types, but there are still some "gotchas." One of C's biggest gotchas is its potentially unsafe casting mechanism. When the new-style casts become available in commercial compilers, a whole heap of debugging headaches should disappear.<P>
<h4><FONT COLOR="#000080"><A name="017B_00D9">Answer to Exercise<A name="017B_00D9"></FONT></h4></P>
Since the value of <I>x</I> is <I>0x7C (124)</I>, in the expression<P>
<pre>x + x</pre>
both occurrences of <I>x</I> are promoted to <I>0x007C</I>, which add to <I>0x00F8</I> &#151; no further conversion takes place. <I>y'</I>s value of <I>0xF8</I>, however, promotes to <I>0xFFF8</I>, because its high-order bit is set.<P>

<h4><a href="../../../source/1994/sep94/allison.zip">Get Article Source Code</a></h4>

</BLOCKQUOTE>
</BODY>
</HTML>

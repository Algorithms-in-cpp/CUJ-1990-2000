

<HTML>
<HEAD>

<TITLE>June 1993/Image Processing, Part 10: Segmentation Using Edges and Gray Shades</TITLE></HEAD>
<body bgcolor="#ffffff">
<H2><A HREF="../tocjun.htm"><IMG SRC="../../toc.gif" ALT="{back to toc}" WIDTH="54" HEIGHT="54"></A><FONT COLOR="#FF0000">   Features</FONT></H2>

<hr><h2 align="center"><font color="#800000">Image Processing, Part 10: Segmentation Using Edges and Gray Shades<A name="014B_0092"><A name="014B_0092"></font></h2><P>
<h3 align="center"><font color="#800000"><A name="014B_0000"><A name="014B_0000">Dwayne Phillips</font></h3><hr><blockquote><P>
<P><i><A name="014B_0000"><A name="014B_0000">The author works as a computer and electronics engineer with the U.S. Department of Defense. He has a PhD in Electrical and Computer Engineering from Louisiana State University. His interests include computer vision, artificial intelligence, software engineering, and programming languages.</i></P><P>
<h4><FONT COLOR="#000080"><A name="014B_0093">Introduction to the Series of Articles<A name="014B_0093"></FONT></h4></P>
This is the tenth in a series of articles on images and image processing. Previous articles discussed reading, writing, displaying, and printing images (TIFF format), histograms, edge detection, spatial frequency filtering, and sundry image operations. This article will discuss image segmentation using edges and gray shades.<P>
The last article (Phillips, February 1993) discussed image segmentation using histograms. That basic technique examined the histogram of an image, transformed the image into a 1-0 image, and "grew" regions. The results were acceptable given the simplicity of the approach.<P>
<h4><FONT COLOR="#000080"><A name="014B_0094">Segmentation Using Edges and Gray Shades<A name="014B_0094"></FONT></h4></P>
There are powerful segmentation techniques that use the edges in an image, grow regions using the gray shades in an image, and use both the edges and gray shades. These techniques work well over a range of images because edges and gray shades are important clues to objects in a scene.<P>
<A href="fig1.htm">Figure 1</a>
shows the result of using edges to segment an image. The left side shows the output of an edge detector. The right side is the result of grouping the pixels "inside" the edges as objects &#151; a triangle and rectangle. This idea is simple. Detect the edges and group the pixels as objects.<P>
<A href="fig2.htm">Figure 2</a>
illustrates growing objects using the gray shades in an image. You group a pixel with a neighboring pixel if their gray shades are close enough. You replace the two pixels with their average and then look at the neighbors of this two pixel object. If the gray shades of the neighbors are close enough, they become part of the object and their values adjust the average gray shade of the object. The left side shows the input, and the right side shows the result of growing objects in this manner. The 1s are the background object produced by grouping the 1s, 2s, and 3s. The triangle of 2s is a grouping of the 7s and 8s, and the rectangle of 3s is the 8s and 9s.<P>
<A href="fig3.htm">Figure 3</a>
combines the two techniques. The left side shows a gray shade image with the output of an edge detector (*s) superimposed. The right side shows the result of growing regions using the gray shades while ignoring the detected edges (*s). The result is the three objects produced in <A href="fig2.htm">Figure 2</a>
separated by the edges.<P>
These three simple techniques work well in ideal situations. Most images, however, are not ideal. Real images and image processing routines introduce problems.<P>
<h4><FONT COLOR="#000080"><A name="014B_0095">Problems<A name="014B_0095"></FONT></h4></P>
You can encounter three potential problems using these segmentation techniques: the input image can have too many edges and objects, the edge detectors may not be good enough, and you may need to exclude unwanted items to effectively grow the region.<P>
The input image can be too complicated and have small, unwanted objects. <A href="photo1.htm">Photograph 1</a>
shows an aerial image of house trailers, roads, lawns, trees, and a tennis court. The white house trailers are obvious and easy to detect. Other objects (tennis court) have marks or spots that fool the edge detectors and region growing routines. <A href="photo2.htm">Photograph 2</a>
shows a house, and <A href="photo3.htm">Photograph 3</a>
shows its edges. Segmentation should detect the roof, windows, and door. The bricks, leaves, and shutter slats are real, but small, so you do not want to detect all of them.<P>
You need high quality edge detection to use these technisques. <A href="fig4.htm">Figure 4</a>
demonstrates how a small edge-detector error leads to a big segmentation error. On the left side of the figure, I poked a small hole in the left edge of the rectangle. The right side shows the terrible segmentation result. Edge detectors do not produce these 1-0 images without thresholding them (Phillips, November 1991). <A href="photo4.htm">Photograph 4</a>
shows the result of edge detection on <A href="photo1.htm">Photograph 1</a>.
 You need to threshold the strong (bright) and weak (faint) edges, to produce a clean 1-0 image. But you also need a consistent and automatic method to find the threshold point. Detected edges can be too thin and too thick. A surplus of stray, thin edges misleads segmentation, and heavy, extra-thick edges ruin objects. <A href="fig5.htm">Figure 5</a>
shows how the triple thick edges on the left side produce the distorted objects on the right side.<P>
The region-growing algorithm (Phillips, January 1992) must limit the size of objects and exclude unwanted pixels. The house in <A href="photo2.htm">Photograph 2</a>
contains objects of widely varying size. You may want to exclude the bricks to concentrate on large objects or vice versa. You may want to omit certain pixels such as edges. The left side of <A href="fig6.htm">Figure 6</a>
is a repeat of <A href="fig1.htm">Figure 1</a>
while the right side shows what happens when the region grower mistakes the edges for objects.<P>
<h4><FONT COLOR="#000080"><A name="014B_0096">Solutions<A name="014B_0096"></FONT></h4></P>
You can solve the edge detection problems by preprocessing, better edge detection, and better region growing.<P>
<h4><FONT COLOR="#000080"><A name="014B_0097">Preprocessing<A name="014B_0097"></FONT></h4></P>
Preprocessing involves smoothing the input image to remove noise, marks, and unwanted detail. The median filter (Phillips, October 1992), one form of smoothing, sorts the pixels in an <I>n</I>x<I>n</I> area (3x3, 5x5, etc.), and replaces the center pixel with the median value. High- and low-pixel filters, variations of the median filter, sort the pixels in an <I>n</I>x<I>n</I> area and replace the center pixel with either the highest or lowest pixel value.<P>
<A href="fig7.htm">Figure 7</a>
illustrates the median, high-pixel, and low-pixel filters. The left side shows the input, the image section. The right side shows the output for each filter processing a 3x3 area. The median filter removes the spikes of the larger numbers. The high-pixel filter output has many high values because the input has a large number in most of its 3x3 areas. The low-pixel filter output is all 1s because there is a 1 in every 3x3 area of the input.<P>
<A href="photo5.htm">Photograph 5</a>
and <A href="photo6.htm">Photograph 6</a>
show how the low-pixel filter reduces the clutter in the edge detector output. <A href="photo5.htm">Photograph 5</a>
is the result of the low-pixel filter applied to <A href="photo2.htm">Photograph 2</a>.
 The dark window shutters are larger, and the mortar lines around the bricks are gone. <A href="photo6.htm">Photograph 6</a>
is the output of the edge detector applied to <A href="photo5.htm">Photograph 5</a>.
 Compare this to <A href="photo3.htm">Photograph 3</a>.
 The edges around the small objects are gone.<P>
<A href="list1.htm">Listing 1</a>
shows the <I>high_pixel</I> and <I>low_pixel</I> subroutines. They create the output image file if needed, read the input image, loop through the data, and write the output. The looping portion places the pixels in the <I>n</I>x<I>n</I> area into the elements array, sorts the array, and places the highest or lowest pixel value into the output image.<P>
<h4><FONT COLOR="#000080"><A name="014B_0098">Improved Edge Detection<A name="014B_0098"></FONT></h4></P>
For effective segmentation you need accurate edge detectors with automatic thresholding of edges and the ability to thin edges.<P>
I improved the accuracy of the edge detectors in the C Image Processing System by adding two more edge detectors and correcting three others (Phillips, November 1991, January 1992). One of the new edge detectors, the variance operator, examines a 3x3 area and replaces the center pixel with the variance. The variance operator subtracts the pixel next to the center pixel, squares that difference, adds up the squares of the differences from the eight neighbors, and takes the square root. The other new edge detector, the range operator, sorts the pixels in an <I>n</I>x<I>n</I> area and subtracts the smallest pixel value from the largest to produce the range.<P>
<A href="fig8.htm">Figure 8</a>
shows the results of applying the variance and range operators to an array of numbers. <A href="photo7.htm">Photograph 7</a>
and <A href="photo8.htm">Photograph 8</a>
show the outcome of applying these operators to the house image of <A href="photo2.htm">photograph 2</a>.
<P>
<A href="list2.htm">Listing 2</a>
shows the source code for the variance and range operators. They create an output image if needed, read the input, loop through the image, and write the output. The looping structure performs the calculations described above.<P>
I corrected a major mistake in the directional edge detectors (Phillips, November 1991) that improved accuracy. The Sobel, Kirsch, and Prewitt edge detectors use eight different 3x3 convolution masks &#151; one mask for each direction. <A href="list3.htm">Listing 3</a>
shows the correction to the subroutine <I>perform_convolution</I> (Phillips, November 1991). A reader noticed I was setting the output to the answer of each direction convolution &#151; not the strongest of all eight directions. To correct this, set the output to the convolution sum only if the sum is greater than the output.<P>
<A href="photo9.htm">Photograph 9</a>
and <A href="photo10.htm">Photograph 10</a>
show the effect of this correction. <A href="photo9.htm">Photograph 9</a>
is from the early article, and the edges are all on the right side and bottom of the objects. There are no edges on the upper and left sides. <A href="photo10.htm">Photograph 10</a>
shows how the correction produced edges without holes and having the quality needed for segmentation.<P>
For effective edge detection you need a technique for thresholding the edge detector output consistently and automatically. One technique sets the threshold point at a given percentage of pixels in the histogram. You calculate the histogram for the edge detector output and sum the histogram values beginning with 0. When this sum exceeds a given percent of the total, you have the threshold value. This method produces consistent results without any manual intervention. A good percentage to use is 50% for most edge detectors and images.<P>
<A href="photo11.htm">Photograph 11</a>
shows the thresholded edge detector output of <A href="photo1.htm">Photograph 1</a>.
 That is, I processed <A href="photo1.htm">Photograph 1</a>
with the edge detector (<A href="photo4.htm">Photograph 4</a>
shows the result) and set the threshold at 70 percent. <A href="list4.htm">Listing 4</a>
shows the <I>find_cutoff_point</I> subroutine that looks through a histogram to find the threshold point. It takes in the histogram and the desired percent and returns the threshold point. This is a simple accumulate and compare operation.<P>
The erosion operation (Russ 1992) can solve the final problem with edge detectors, removing extra edges and thinning thick edges. Erosion looks at pixels turned on (edge detector outputs) and turns them off if they have enough neighbors that are turned off. <A href="fig9.htm">Figure 9</a>
and <A href="fig10.htm">Figure 10</a>
illustrate erosion. In <A href="fig9.htm">Figure 9</a>,
  the left side shows edges (1s) around the triangle and rectangle and then several stray edges. The right side shows the result of eroding or removing any 1 that has seven 0 neighbors. In <A href="fig10.htm">Figure 10</a>,
 the left side shows very thick edges around the triangle and rectangle. The right side shows the result of eroding any 1 that has three 0 neighbors. The edges are thinner, and the objects inside the edges are more accurate.<P>
<A href="list5.htm">Listing 5</a>
shows the erosion subroutine <I>erode_image_array</I>. The looping structure examines every pixel in <I>the_image</I> that equals value. It counts the number of neighboring 0 pixels and sets the <I>out_image</I> to zero if this count exceeds the threshold parameter. The threshold parameter controls the erosion. Threshold was 6 in <A href="fig9.htm">Figure 9</a>
and 2 in <A href="fig10.htm">Figure 10</a>.
<P>
<A href="photo12.htm">Photograph 12</a>
shows the result of eroding the thick edges of <A href="photo6.htm">Photograph 6</a>.
 Note how it thinned the thick edges and removed the stray edges in the house, lawn, and tree. The threshold parameter was 3 for this example.<P>
<h4><FONT COLOR="#000080"><A name="014B_0099">Improved Region Growing<A name="014B_0099"></FONT></h4></P>
You need accurate region growing to implement the edge and gray shade segmentation techniques. <A href="fig11.htm">Figure 11</a>
shows the region-growing algorithm used in the last article (Phillips, February 1993). This worked for binary images containing 0s and a value. If the algorithm found a pixel equal to <I>value</I>, it labeled that pixel and checked its neighbors to see if they also equaled <I>value</I> (step 3).<P>
The region-growing algorithm needs improvements to work with any gray shades, limit the size of regions, and exclude pixels with special values (like edges). <A href="fig12.htm">Figure 12</a>
shows the new region-growing algorithm. The input image <I>g</I> contains gray shades and may contain special pixels equal to <I>FORGET_IT.</I> The output image array holds the result. There are three new parameters: <I>diff</I>, <I>min_area</I>, and <I>max_area. diff</I> specifies the allowable difference in gray shade for two pixels to merge into the same object. <I>min_area</I> and <I>max_area</I> specify the limits on the size of objects.<P>
The major differences in the algorithm begin at step 4. Instead of checking if <I>g(i</I>,<I>j)</I> == value, the algorithm performs three checks:<P>
<UL><li><I>g(i</I>,<I>j)</I> cannot equal <I>FORGET_IT</I></li>
<li><I>output(i</I>,<I>j)</I> must equal zero</li>
<li><I>g(i</I>,<I>j)</I> cannot differ from the target by more than <I>diff</I></li></UL>
The first two are simple. You want to exclude certain pixels, so you set them to <I>FORGET_IT</I> and ignore them. The output must not be part of an object, so it must be zero.<P>
The third test allows you to work with gray shade images. In step 3, you create a target equal to the average gray shade of the pixels in an object. You group neighboring pixels whose values do not differ by more than the <I>diff</I> parameter. The <I>is_close</I> routine at the bottom of <A href="fig12.htm">Figure 12</a>
tests for this condition. If the pixel <I>g(i</I>,<I>j)</I> is close enough to the target, you call the <I>pixel_label_and_check_neighbor</I> routine to add that pixel to the object and check its neighbors. The <I>pixel_label_and_check_neighbor</I> routine updates the target or average gray shade of the object.<P>
The new algorithm limits the size of objects in step 6. It tests <I>count</I> (the size of an object) against <I>min_area</I> and <I>max_area.</I> If the object fails the test, you set all pixels of <I>g</I> in  the object to <I>FORGET_IT</I> and set all pixels in output to 0. This removes the object from output and eliminates the pixels from any future consideration in <I>g.</I><P>
I've already discussed how the new algorithm excludes pixels with certain values via the <I>FORGET_IT</I> value. If you want to remove edges from consideration, you lay the edge detector output on top of the input image and set to <I>FORGET_IT</I> all pixels corresponding to the edges.<P>
<A href="list6.htm">Listing 6</a>
shows the source code for the three subroutines outlined in <A href="fig12.htm">Figure 12</a>.
 They follow the algorithm closely. The only trick is how to implement the stack (Phillips, February 1993).<P>
The improved region-growing algorithm is the key to the new techniques. It ignores certain pixels and eliminates objects of the wrong size. These small additions produce segmentation results that are much better than those from Part 9.<P>
<h4><FONT COLOR="#000080"><A name="014B_009A">The Three New Techniques<A name="014B_009A"></FONT></h4></P>
Now that I've laid all the ground work, I'll go on to the three new techniques.<P>
<h4><FONT COLOR="#000080"><A name="014B_009B">Edges Only<A name="014B_009B"></FONT></h4></P>
The <I>edge_region</I> subroutine shown in <A href="list7.htm">Listing 7</a>
implements this technique. The algorithm is<P>
1.     Create the output image file if needed<P>
2.     Read the input image<P>
3.     Edge detect the input image<P>
4.     Threshold the edge detector output<P>
5.     Erode the edges if desired<P>
6.     Set the edge values to FORGET_IT<P>
7.     Grow the objects while ignoring the edges<P>
Steps 1 through 6 should give you an image like that shown in <A href="fig1.htm">Figure 1</a>.
 Step 7 grows the objects as outlined by the edges. The <I>edge_region</I> subroutine calls any of the edge detectors from this and previous articles, the histogram functions from previous articles, and the <I>find_cutoff_point</I>,<I> erode_image_array</I>, and <I>pixel_grow</I> functions from <A href="list4.htm">Listing 4</a>,
 <A href="list5.htm">Listing 5</a>,
 and <A href="list6.htm">Listing 6</a>.
<P>
The <I>edge_type</I> parameter specifies which edge detector to use. <I>min_area</I> and <I>max_area</I> pass through to the <I>pixel_grow</I> routine to constrain the size of the objects detected. <I>diff</I> passes through to <I>pixel_grow</I> to set the tolerance on gray shades added to an object. <I>diff</I> has little meaning for this technique because the image in which you grow regions contains only 0s and <I>FORGET_IT</I> pixels. The percent parameter passes through to the <I>find_cutoff_point</I> routine to threshold the edge detector output. The <I>set_value</I> parameter is the turned on pixel in the <I>threshold_image_array</I> and <I>erode_image_array</I> routines. Finally, the <I>erode</I> parameter determines whether you perform erosion on the edge detector output. If erode is not zero, then it is the threshold parameter for <I>erode_image_array</I>.<P>
<h4><FONT COLOR="#000080"><A name="014B_009C">Gray Shades Only<A name="014B_009C"></FONT></h4></P>
The short <I>gray_shade_region</I> subroutine in <A href="list8.htm">Listing 8</a>
implements this technique. This subroutine creates an output image file if needed and calls the <I>pixel_grow</I> function of <A href="list6.htm">Listing 6</a>.
 <I>pixel_grow</I> does all the work since it handles the gray-shade region growing and limits the sizes of the objects. The <I>diff</I>, <I>min_area</I>, and <I>max_area</I> parameters play the same role as in the <I>edge_region</I> routine described above.<P>
<h4><FONT COLOR="#000080"><A name="014B_009D">Edges and Gray Shade Combined<A name="014B_009D"></FONT></h4></P>
The technique for combining edges and gray shades is implemented by the <I>edge_gray_shade_region</I> function in <A href="list9.htm">Listing 9</a>.
 The algorithm is<P>
1.     Create the output image file if needed<P>
2.     Read the input image<P>
3.     Edge detect the input image<P>
4.     Threshold the edge detector output<P>
5.     Erode the edges if desired<P>
6.     Read the input image again<P>
7.     Put the edge values on top of the input image setting them to FORGET_IT<P>
8.     Grow gray shade regions while ignoring the edges<P>
The differences between <I>edge_region</I> and <I>edge_gray_shade_region</I> are in steps 6 and 7. At this point, <I>edge_gray_shade_region</I> reads the original input image again and overlays it with the detected edges. Step 8 grows gray shade regions while ignoring the detected edges. Steps 1 through 7 generate an image like the left side of <A href="fig3.htm">Figure 3</a>.
 Step 8 generates the right side of <A href="fig3.htm">Figure 3</a>.
<P>
<A href="photo13.htm">Photograph 13</a>
through <A href="photo17.htm">Photograph 17</a>
illustrate these techniques on the aerial image of <A href="photo1.htm">Photograph 1</a>.
 <A href="photo13.htm">Photograph 13</a>
shows the result of the Sobel edge after erosion. The edges outline the major objects in the image fairly well.<P>
<A href="photo14.htm">Photograph 14</a>
shows the result of the edge-only segmentation of <A href="photo1.htm">Photograph 1</a>.
 It is result of growing the black regions of <A href="photo13.htm">Photograph 13</a>.
 This is a good segmentation as it denotes the house trailers, roads, trees, and parking lots. This is not just the negative image of <A href="photo13.htm">Photograph 13</a>.
 Regions too small and large were eliminated.<P>
<A href="photo15.htm">Photograph 15</a>
is the result of the gray-shade-only segmentation of <A href="photo1.htm">Photograph 1</a>.
 This segmentation also found the major objects in the image. The combination of edge and gray shade segmentation in <A href="photo16.htm">Photograph 16</a>
shows the edges of <A href="photo13.htm">Photograph 13</a>
laid on top of the input image of <A href="photo1.htm">Photograph 1</a>.
 <A href="photo17.htm">Photograph 17</a>
shows the final result of growing gray-shade regions inside these edges. This segmentation has better separation of objects than the gray-shade-only segmentation of <A href="photo15.htm">Photograph 15</a>.
 The edges between the objects caused this spacing.<P>
Which segmentation is best? That is a judgement call. All three segmentations, however, are better than those produced by the simple techniques in the last article.<P>
<A href="photo18.htm">Photograph 18</a>,
 <A href="photo19.htm">Photograph 19</a>,
 and <A href="photo20.htm">Photograph 20</a>
show the results of the three techniques applied to the house image of <A href="photo2.htm">Photograph 2</a>.
 The edge-only segmentation of <A href="photo18.htm">Photograph 18</a>
is fairly good as it denotes most of the major objects in the image. The gray-shade-only result in <A href="photo19.htm">Photograph 19</a>
is not very good because all the objects are right next to each other and hard to distinguish. The combination segmentation in <A href="photo20.htm">Photograph 20</a>
is an excellent result. It detected objects not found in the edge-only technique and also eliminated many of the unwanted bricks.<P>
<h4><FONT COLOR="#000080"><A name="014B_009E">Integrating the New Techniques<A name="014B_009E"></FONT></h4></P>
<A href="list10.htm">Listing 10</a>
shows the new code for the main routine of the C Image Processing System (CIPS). I added case 18 to allow segmentation using the three techniques discussed here. Given next are the changes to the CIPS main menu and the routine that interacts with the user to obtain all the options.<P>
<A href="list11.htm">Listing 11</a>
shows a standalone application program for segmenting entire images using the new techniques. It is command-line driven and calls the functions given in the previous listings.<P>
<h4><FONT COLOR="#000080"><A name="014B_009F">Conclusions<A name="014B_009F"></FONT></h4></P>
This installment in the series described three powerful image segmentation techniques that work on complicated  ages. The techniques, however, are only combinations of existing tools and tricks. Given different images, you might have used different combinations of tools. Experiment, try different combinations, and modify existing tools to create new ones.<P>
<h4>References</FONT></h4></P>
Phillips, Dwayne. November 1991. "Image Processing, Part 5: Writing Images to Files and Basic Edge Detection," <I>The C Users Journal</I>. Lawrence, KS: R&amp;D Publicatons.<P>
Phillips, Dwayne. January 1992. "Image Processing, Part 6: Advanced Edge Detection," <I>The C Users Journal</I>. Lawrence, KS: R&amp;D Publications.<P>
Phillips, Dwayne. October 1992. "Image Processing, Part 7: Spatial Frequency Filtering," <I>The C Users Journal</I>. Lawrence, KS: R&amp;D Publications.<P>
Russ, John C. 1992. <I>The Image Processing Handbook</I>. Boca Raton, FL: CRC Press.<P>
Phillips, Dwayne. February 1993. "Image Processing, Part 9: Histogram-Based Image Segmentation," <I>The C Users Journal</I>. Lawrence, KS: R&amp;D Publications.<P>

<h4><a href="../../../source/1993/jun93/phillips.zip">Get Article Source Code</a></h4>

</BLOCKQUOTE>
</BODY>
</HTML>
